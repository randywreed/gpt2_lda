{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Classify gpt2 as religion.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ilhv9SBGEPBQ",
        "temkUO25ukEh",
        "EV3xHF-OukFL",
        "lxkvAQ5LacHg",
        "gVBfdshWukGA"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/randywreed/gpt2_lda/blob/master/Classify_gpt2_as_religion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P98_trwB_uf9",
        "colab_type": "text"
      },
      "source": [
        "## Setup (always run this)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0olZRWVRukCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwwhHOCFAFX5",
        "colab_type": "text"
      },
      "source": [
        "## MODIFY THE FOLLOWING CELLS: \n",
        "You must have already created a folder in your google drive for use<br>\n",
        "The next two cells give colab permission to use your google drive (you will do this twice)<br>\n",
        "In the following cell change the *paulaidir* to google drive directory to store models and data<br>\n",
        "change *trans* to the tranlation (should correspond to the .csv file name)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrmzDJuqvAeh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "6878daa1-5d6c-483a-bf41-345967be5c1d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpCwf-MPukCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gspread\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQoukQFF4KEY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#set paulaidir to you google drive directory\n",
        "#trans should be equivalent to the .csv file for the full translation (i.e. niv.csv)\n",
        "#if you need to see a list of csv files continue down, and then come back, change and re-run this cell\n",
        "paulaidir='/content/drive/My Drive/AI & Tech Research/Religion of GPT2/'\n",
        "trans=\"wikipedia_relwcat - wikipedia_relwcat\"\n",
        "myemail=\"reedrw@appstate.edu\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12OUvVdsukDg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1ce785f7-e68e-4540-cca0-fc84ae6a9bb6"
      },
      "source": [
        "from pathlib import Path\n",
        "paulpath=Path(paulaidir)\n",
        "print(paulpath)\n",
        "path=Path(paulaidir+'fastai/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbD4pG7J1heu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "a3fc880f-ada5-4a78-96f9-65ee6a36c028"
      },
      "source": [
        "#to see a list of .csv files remove the # from the following lines of the cell\n",
        "import glob\n",
        "for filename in glob.glob(str(paulpath)+\"/*.csv\"):\n",
        "  print(filename)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2/DedooseCodesExport_2020_3_25_1533.csv\n",
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2/newults.csv\n",
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2/T4Results.csv\n",
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2/wiki.csv\n",
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2/wikip_00.csv\n",
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2/wikip_01.csv\n",
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2/wikip_03.csv\n",
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2/wikip_06.csv\n",
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2/wikip_04.csv\n",
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2/wikip_05.csv\n",
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2/wikip_07.csv\n",
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2/wikip_08.csv\n",
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2/wikip_09.csv\n",
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2/wikip_10.csv\n",
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2/wikip_11.csv\n",
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2/wikip_12.csv\n",
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2/wikip_13.csv\n",
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2/wikip_14.csv\n",
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2/wikip_15.csv\n",
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2/wikip_02.csv\n",
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2/wikipedia_rel.csv\n",
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2/topics.csv\n",
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2/all_articles.csv\n",
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2/wiki_secular.csv\n",
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2/wikipedia_relwcat - wikipedia_relwcat.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Yrb_UgDukDj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e12c76c3-ef1c-47c0-986b-04273a1a36cd"
      },
      "source": [
        "translation=trans+\".csv\"  \n",
        "file=paulaidir+translation\n",
        "file"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/AI & Tech Research/Religion of GPT2/wikipedia_relwcat - wikipedia_relwcat.csv'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF6BllkBfRhf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade -q gspread\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSAC7sBrukCv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "3e86f3e0-4c06-4c58-9f60-cb5e497f5aa2"
      },
      "source": [
        "pip install PyOpenSSL"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting PyOpenSSL\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/de/f8342b68fa9e981d348039954657bdf681b2ab93de27443be51865ffa310/pyOpenSSL-19.1.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 4.5MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/04/686efee2dcdd25aecf357992e7d9362f443eb182ecd623f882bc9f7a6bba/cryptography-2.9.2-cp35-abi3-manylinux2010_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 14.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.6/dist-packages (from PyOpenSSL) (1.12.0)\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.8->PyOpenSSL) (1.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.8->PyOpenSSL) (2.20)\n",
            "Installing collected packages: cryptography, PyOpenSSL\n",
            "Successfully installed PyOpenSSL-19.1.0 cryptography-2.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnrmyU_xHrIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getloggerdt():\n",
        "  import pytz\n",
        "  from datetime import datetime\n",
        "  now = datetime.now(pytz.timezone('America/New_York'))\n",
        "  \n",
        "  log_ent=now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
        "  return log_ent\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhxwEA9FNNQ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "97a0992d-6927-42f9-e46b-0cd313d7d665"
      },
      "source": [
        "logfilename=trans+\"_log\"\n",
        "print(logfilename)\n",
        "\n",
        "try:\n",
        "  logwriter=gc.open(logfilename).sheet1\n",
        "except Exception:\n",
        "  logsh=gc.create(logfilename)\n",
        "  logsh.share(myemail,perm_type='user',role='writer')\n",
        "  logwriter=logsh.get_worksheet(0)\n",
        "\n",
        "logwriter.append_row([getloggerdt(),'start log'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "wikipedia_relwcat - wikipedia_relwcat_log\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1RyYJaX1ysSAo4JpXhbRVcrRm1UGV3oUI7SGLg1rwzUs',\n",
              " 'tableRange': 'Sheet1!A1:B9',\n",
              " 'updates': {'spreadsheetId': '1RyYJaX1ysSAo4JpXhbRVcrRm1UGV3oUI7SGLg1rwzUs',\n",
              "  'updatedCells': 2,\n",
              "  'updatedColumns': 2,\n",
              "  'updatedRange': 'Sheet1!A10:B10',\n",
              "  'updatedRows': 1}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS8fGY1BukC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run this if fixing an UNAUTHENTICATED error for the spreadsheet\n",
        "try:\n",
        "  worksheet = gc.open(\"PaulAI_Experiments_\"+trans).sheet1\n",
        "except Exception:\n",
        "  spreadsh=gc.create(\"PaulAI_Experiments_\"+trans)\n",
        "  spreadsh.share(myemail,perm_type='user',role='writer')\n",
        "  worksheet=spreadsh.get_worksheet(0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnOmL9vwukDA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "c86aebca-ccfa-4149-c32a-76b65aed66d0"
      },
      "source": [
        "!pip install --pre torch torchvision -f https://download.pytorch.org/whl/nightly/cu102/torch_nightly.html\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/nightly/cu102/torch_nightly.html\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.5.1+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.6.1+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWOHr8LSukDC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.distributed import *\n",
        "import argparse"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY5-_USvukDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai import *\n",
        "from fastai.text import *"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3IzlDAAukDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.callbacks import SaveModelCallback"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ghKapI0ukDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import fastai.utils.collect_env\n",
        "\n",
        "# fastai.utils.collect_env.show_install()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVG8jD8wukDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Config.DEFAULT_CONFIG={\n",
        "    'data_path': paulaidir+'fastai/data',\n",
        "    'model_path': paulaidir+'fastai/model'\n",
        "}\n",
        "Config.create(paulaidir+'fastai/myconfig.yml')\n",
        "Config.DEFAULT_CONFIG_PATH=paulaidir+'fastai/myconfig.yml'"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaBo312AukDU",
        "colab_type": "text"
      },
      "source": [
        "Note that language models can use a lot of GPU, so you may need to decrease batchsize here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgl60TU8ukDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# bs=48\n",
        "# bs=24\n",
        "bs=96"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XpMFzjLukDX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7c99fff3-ffe9-4ac0-f498-96665eb8dac5"
      },
      "source": [
        "#distributed Processing setup\n",
        "#parser = argparse.ArgumentParser()\n",
        "#parser.add_argument(\"--local_rank\", type=int)\n",
        "#args = parser.parse_args()\n",
        "#torch.cuda.set_device(args.local_rank)\n",
        "#torch.distributed.init_process_group(backend='nccl', init_method='env://')\n",
        "bs\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1j2GlX5ukDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "torch.cuda.set_device(0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX1vxPIRBcwi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "7cdf40d1-6bd4-429d-ceb0-90b86e28056d"
      },
      "source": [
        "logwriter.append_row([getloggerdt(),'setup complete'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1RyYJaX1ysSAo4JpXhbRVcrRm1UGV3oUI7SGLg1rwzUs',\n",
              " 'tableRange': 'Sheet1!A1:B4',\n",
              " 'updates': {'spreadsheetId': '1RyYJaX1ysSAo4JpXhbRVcrRm1UGV3oUI7SGLg1rwzUs',\n",
              "  'updatedCells': 2,\n",
              "  'updatedColumns': 2,\n",
              "  'updatedRange': 'Sheet1!A5:B5',\n",
              "  'updatedRows': 1}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i68zFP08ukDe",
        "colab_type": "text"
      },
      "source": [
        "### Language model (Always Run)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16_tfWMwukDf",
        "colab_type": "text"
      },
      "source": [
        "Now let's grab the full dataset for what follows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gGQSiodnnzU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7990e6d2-390b-4404-9727-a3db6c457e1a"
      },
      "source": [
        "file"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/AI & Tech Research/Religion of GPT2/wikipedia_relwcat - wikipedia_relwcat.csv'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKGqu66mukDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg5uW-A7o98u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "relfile=Path('/content/drive/My Drive/AI & Tech Research/Religion of GPT2/fastai/data/wikipedia_relwcat - wikipedia_relwcat.csv')\n",
        "secfile=Path('/content/drive/My Drive/AI & Tech Research/Religion of GPT2/fastai/data/wiki_secular.csv')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tX-OeY9sQN-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b1574287-8461-454e-9581-1f1708aa4ad0"
      },
      "source": [
        "print(relfile)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2/fastai/data/wikipedia_relwcat - wikipedia_relwcat.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sVmgAEzukDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#read csvs into pandaas dataframe\n",
        "rel=pd.read_csv(relfile)\n",
        "sec=pd.read_csv(secfile)\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmnxHT_wpyCu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ef79f106-8f8d-433f-c8d9-7cdc989b8375"
      },
      "source": [
        "print (rel.columns)\n",
        "print(sec.columns)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Topic', 'Text', 'Flag'], dtype='object')\n",
            "Index(['title', 'text', 'rel'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcF62_eOp601",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sec.columns=['Topic','Text','Flag']\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9XYe3DEqKar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#set secular to S, religious to r\n",
        "rel.Flag='R'\n",
        "sec.Flag='S'"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FO7GgE9qYth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#merge two files\n",
        "df=pd.concat([rel,sec])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFqKyV_dtNWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fills any blank article with just the topic to allow processing, but need to fix this\n",
        "df.Text.fillna(df.Topic,inplace=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK5jqHiJsayY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "e60c7645-44cd-4c52-ca50-99167656ea4c"
      },
      "source": [
        "#check text for na's\n",
        "df[df['Text'].isna()]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic</th>\n",
              "      <th>Text</th>\n",
              "      <th>Flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Topic, Text, Flag]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "EC9wyi9wukD6",
        "colab_type": "text"
      },
      "source": [
        "#### Creating the TextLMDataBunch (if run once, skip to loading saved data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "Fh9HvSiNukD7",
        "colab_type": "text"
      },
      "source": [
        "We have to use a special kind of `TextDataBunch` for the language model, that ignores the labels (that's why we put 0 everywhere), will shuffle the texts at each epoch before concatenating them all together (only for training, we don't shuffle for the validation set) and will send batches that read that text in order with targets that are the next word in the sentence.\n",
        "\n",
        "The line before being a bit long, we want to load quickly the final ids by using the following cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUrJewjZukD3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "18653d79-a9e6-4e35-8087-24d57cc60a36"
      },
      "source": [
        "data_lm=TextLMDataBunch.from_df(path, train_df=df, valid_df=df, text_cols=\"Text\",bs=bs)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "GyOCJWw1ukD8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "0dc036d7-aac4-471f-cb29-1f7328b793f4"
      },
      "source": [
        "data_lm.show_batch()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:134: UserWarning: \n",
            "    Found GPU0 Tesla T4 which requires CUDA_VERSION >= 10000 to\n",
            "     work properly, but your PyTorch was compiled\n",
            "     with CUDA_VERSION 9000. Please install the correct PyTorch binary\n",
            "     using instructions from https://pytorch.org\n",
            "    \n",
            "  warnings.warn(incorrect_binary_warn % (d, name, 10000, CUDA_VERSION))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>to it . \\n  xxmaj if you click on \" xxmaj related changes \" at the side of this page , you will see a list of the most recent changes in articles to which this page links . xxmaj this page links to itself and its talk page so that changes to them can be tracked by the same means . \\n \\n \\n  = = xxunk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>( xxmaj greek \" baptize \" ) , they do not eat \" , and \" baptize \" where xxunk , the new xxmaj christian rite , is intended . xxmaj the older ritual washing use of xxunk is relevant in the context of funerals since any xxmaj jew coming into contact with the dead body must undertake ritual washing . xxmaj during the xxmaj second xxmaj temple and early</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>functional xxmaj christology \" analyzes the works of xxmaj jesus xxmaj christ , while \" soteriological xxmaj christology \" analyzes the \" salvific \" xxunk of xxmaj christology . xxmaj several approaches can be distinguished within xxmaj christology . xxmaj the term \" xxmaj christology from above \" or \" high xxmaj christology \" refers to approaches that include aspects of divinity , such as xxmaj lord and xxmaj son</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>other than the creator will cease to exist , except xxmaj osiris , who will survive along with him . xxmaj details about this eschatological prospect are left unclear , including the fate of the dead who are associated with xxmaj osiris . xxmaj yet with the creator god and the god of renewal together in the waters that gave rise to the orderly world , there is the potential</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>xxmaj xxunk xxunk states , \" xxmaj just as these ancient martyrs were revealed once more , xxmaj catholics were beginning to be martyred afresh , both in mission fields overseas and in the struggle to win back xxmaj protestant northern xxmaj europe : the catacombs proved to be an inspiration for many to action and to heroism . xxunk missions were carried to new places beginning with the new</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55tlSIdIxSwp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7646f466-b678-4592-fcd5-3fed819df375"
      },
      "source": [
        "print (paulpath)\n",
        "print(path)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2\n",
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2/fastai\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "qcLPVAEjukD-",
        "colab_type": "text"
      },
      "source": [
        "Let's save our databunch for next time:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "-JQjYErLukD_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "add9dcbb-51d2-4ce9-f5bd-54b69db39a42"
      },
      "source": [
        "data_lm.path=path\n",
        "print (data_lm.path)\n",
        "\n",
        "data_lm.save('lm_databunch_'+trans)\n",
        "#logwriter.append_row([getloggerdt(),'databunch saved as lm_databuch_'+trans])\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-7889f2c00dc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lm_databunch_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#logwriter.append_row([getloggerdt(),'databunch saved as lm_databuch_'+trans])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data_lm' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6mNXRpmukEA",
        "colab_type": "text"
      },
      "source": [
        "### Loading saved data, and creating the language model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nhZvov8ukEB",
        "colab_type": "text"
      },
      "source": [
        "In the future we can load the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx28fAxjukEC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "c433352c-01c0-408e-d79e-fedb68c5bca9"
      },
      "source": [
        "data_lm = load_data(path, 'lm_databunch_'+trans, bs=bs)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'torch.nn.modules.loss.CrossEntropyLoss' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6OBSTE0ukEE",
        "colab_type": "text"
      },
      "source": [
        "We can then put this in a learner object very easily with a model loaded with the pretrained weights. They'll be downloaded the first time you'll execute the following line and stored in `~/.fastai/models/` (or elsewhere if you specified different paths in your config file)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "oInIfpidukEE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef07f000-f2b0-4b07-e282-5ab4d1d7cb8a"
      },
      "source": [
        "learn_lm = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)\n",
        "#logwriter.append_row([getloggerdt(),'learner created'])\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://s3.amazonaws.com/fast-ai-modelzoo/wt103-fwd.tgz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSOxD4adukEG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f9ac15a3-8ec1-489b-a401-ca98df809cdf"
      },
      "source": [
        "Config.DEFAULT_CONFIG\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data_archive_path': '/root/.fastai/data',\n",
              " 'data_path': '/root/.fastai/data',\n",
              " 'model_path': '/root/.fastai/models'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euo2UG1zukEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wiki_itos = pickle.load(open(Config().model_path()/'wt103-fwd/itos_wt103.pkl', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilhv9SBGEPBQ",
        "colab_type": "text"
      },
      "source": [
        "### vocabulary Tests (can skip)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3WzooFBukEL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "cf6fca1a-ad2a-4831-abd3-8e3e1cf6725c"
      },
      "source": [
        "wiki_itos[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['xxunk',\n",
              " 'xxpad',\n",
              " 'xxbos',\n",
              " 'xxeos',\n",
              " 'xxfld',\n",
              " 'xxmaj',\n",
              " 'xxup',\n",
              " 'xxrep',\n",
              " 'xxwrep',\n",
              " 'the']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFGKGl_RukEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = data_lm.vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3c7VtSnukEO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b6bb725f-7996-4ff6-a993-be3454aae6fd"
      },
      "source": [
        "vocab.stoi[\"eloi\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9496"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YY3GxoTdukER",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de984571-52fe-4a9d-8bdf-3636b8f3f1b0"
      },
      "source": [
        "vocab.itos[vocab.stoi[\"eloi\"]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eloi'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WdA_wzrukET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "819d2b38-8d17-41a8-a225-61a7cb62e30f"
      },
      "source": [
        "\"eloi\" in wiki_itos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vf2ayehwukEX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "547d0a67-d22c-42d3-e534-dee034907543"
      },
      "source": [
        "vocab.itos[vocab.stoi[\"mobula\"]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xxunk'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTyh5BUzukEY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "awd = learn_lm.model[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "temkUO25ukEh",
        "colab_type": "text"
      },
      "source": [
        "### Difference in vocabulary between Bible translation and Wikipedia (can skip)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "Ev71RW_vukEh",
        "colab_type": "text"
      },
      "source": [
        "We are going to load wiki_itos, which can be downloaded along with wikitext-103.  We will compare the vocabulary from wikitext with the vocabulary in Bible translation.  It is to be expected that the two sets have some different vocabulary words, and that is no problem for transfer learning!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yH3jmJnukEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.spatial.distance import cosine as dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-Xu5EZoukEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc = learn_lm.model[0].encoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb4J6P1_ukEf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a4a8e6f-ca5d-4010-a444-be6b6bdfc03c"
      },
      "source": [
        "enc.weight.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([9776, 400])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "7H1TyzmPukEj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "074c740b-88af-4692-cb93-08257a0cd7ef"
      },
      "source": [
        "len(wiki_itos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "Vi3mSYy0ukEk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19b7e05e-2be9-45ad-9105-a4d461bc97d4"
      },
      "source": [
        "len(vocab.itos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9776"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "EDxAW8k2ukEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i, unks = 0, []\n",
        "while len(unks) < 50:\n",
        "    if data_lm.vocab.itos[i] not in wiki_itos: unks.append((i,data_lm.vocab.itos[i]))\n",
        "    i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "eXaXNlkPukEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wiki_words = set(wiki_itos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "pQnS0V7PukEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bible_words = set(vocab.itos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "RPkaROIGukEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wiki_not_bible = wiki_words.difference(bible_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "Uo-ULUKpukEv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bible_not_wiki = bible_words.difference(wiki_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "CfEm_zNQukEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wiki_not_bible_list = []\n",
        "\n",
        "for i in range(100):\n",
        "    word = wiki_not_bible.pop()\n",
        "    wiki_not_bible_list.append(word)\n",
        "    wiki_not_bible.add(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "scrolled": true,
        "id": "ZUvZ1K98ukEy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "a85f1be7-241f-4b18-9bf8-cc9f69d0d2e2"
      },
      "source": [
        "wiki_not_bible_list[:15]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['oases',\n",
              " 'approving',\n",
              " 'tuck',\n",
              " 'aphid',\n",
              " 'haines',\n",
              " 'sōryū',\n",
              " 'pasties',\n",
              " '1101',\n",
              " 'hønefoss',\n",
              " '402',\n",
              " 'unwritten',\n",
              " 'svetlana',\n",
              " 'ipo',\n",
              " 'fimi',\n",
              " '31.2']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "5Yhu_lhXukEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bible_not_wiki_list = []\n",
        "\n",
        "for i in range(100):\n",
        "    word = bible_not_wiki.pop()\n",
        "    bible_not_wiki_list.append(word)\n",
        "    bible_not_wiki.add(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "2DEwwpRNukE3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "10019f17-f7cf-4189-e512-57281d2e5f65"
      },
      "source": [
        "bible_not_wiki_list[:15]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ibleam',\n",
              " 'galatia',\n",
              " 'jehoiarib',\n",
              " 'hachilah',\n",
              " 'elpaal',\n",
              " 'epaphras',\n",
              " 'iddo',\n",
              " 'buzite',\n",
              " 'grope',\n",
              " 'tubal',\n",
              " 'zanoah',\n",
              " 'arvad',\n",
              " 'hasupha',\n",
              " 'blasphemies',\n",
              " 'premeditation']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "ikrGdcaPukE5",
        "colab_type": "text"
      },
      "source": [
        "All words that appear in the IMDB vocab, but not the wikitext-103 vocab, will be initialized to the same random vector in a model.  As the model trains, we will learn these weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwTfXsUTzejG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test words\n",
        "unique_wiki_words=\"modernisation\"\n",
        "common_word=\"house\"\n",
        "unique_bible_word1=\"blasphemies\"\n",
        "unique_bible_words2=\"displeasing\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "S-OGeMOaukE5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e6a0f62-5a5d-4a8c-8554-6b410d86e8bb"
      },
      "source": [
        "vocab.stoi[unique_wiki_words]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "qQ4l1YnRukE7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b71d095-eb16-4459-ceda-64ababc04de1"
      },
      "source": [
        "unique_wiki_words in wiki_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "Xix0Mw29ukE-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a79058cb-9e75-497d-c12e-c58ebf4d09b3"
      },
      "source": [
        "vocab.stoi[unique_bible_word1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5193"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "Jtv6uVAcukFA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d21f0e3-3df1-4916-e758-7b4177db858b"
      },
      "source": [
        "unique_bible_word1 in wiki_words, unique_bible_word1 in bible_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(False, True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "X3pEivi3ukFB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "faac8ceb-32ab-41d9-feb7-1c4caaf3839f"
      },
      "source": [
        "vocab.stoi[unique_bible_words2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4559"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "pdQAG7mfukFD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63d83366-056d-4165-e920-308483de80ad"
      },
      "source": [
        "unique_bible_words2 in wiki_words, unique_bible_words2 in bible_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(False, True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "scrolled": true,
        "id": "7EjJkPYOukFF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "86c4b87f-7680-4795-d356-65c83bb4f1ac"
      },
      "source": [
        "common_word in wiki_words, common_word in bible_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "zwPMLuQKukFG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09d1b1f0-d421-4a57-bd28-d1df9589d01b"
      },
      "source": [
        "np.allclose(enc.weight[vocab.stoi[unique_bible_word1], :], \n",
        "            enc.weight[vocab.stoi[unique_bible_words2], :])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "cOe-T9UDukFI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0dc2bdc-6da5-44d3-fc00-d5754bcab52e"
      },
      "source": [
        "np.allclose(enc.weight[vocab.stoi[unique_bible_word1], :], \n",
        "            enc.weight[vocab.stoi[common_word], :])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "OVJsME0tukFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_word_vec = enc.weight[vocab.stoi[unique_bible_word1], :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "EV3xHF-OukFL",
        "colab_type": "text"
      },
      "source": [
        "### Generating fake Bible texts (using wiki-text model) (can skip)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "oubCEA5BukFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = \"The color of the sky is\"\n",
        "N_WORDS = 40\n",
        "N_SENTENCES = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "scrolled": false,
        "id": "64gELVqTukFP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "3515082b-2b59-4b65-c9dd-f92f2c19323d"
      },
      "source": [
        "print(\"\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The color of the sky is not used in any of the Star Wars , and it is often explained that the Star Wars Star Wars - inspired Star Wars Dark Shadows War and\n",
            "The color of the sky is displayed in the main character and the character is entirely blue in color . The character appears as a red figure in the two - part character The Boat Race . The character first appears\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "3LUmZ9QrukFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = \"And Jesus said\"\n",
        "N_WORDS = 30\n",
        "N_SENTENCES = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "48GIOx7dukFS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d82c6cae-f889-42db-ba64-15c67f93a996"
      },
      "source": [
        "print(\"\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "And Jesus said they would not love Jesus Christ because they would never love Jesus . Jesus will come to a cure with Jesus Christ and\n",
            "And Jesus said they were not God and Jesus Christ , Jesus Christ the Jesus Christ , Jesus Christ Christ , and\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHZ8E27ibKq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = \"I, Paul, an apostle\"\n",
        "N_WORDS = 30\n",
        "N_SENTENCES = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "scrolled": true,
        "id": "XgrSm66kukFT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "e6e2ebb3-d877-4894-829b-83d107f6e324"
      },
      "source": [
        "print(\"\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I, Paul, an apostle and a Christian Christian , was part of the Congregation for the Religion of Jesus Christ of Latter - day Saints (\n",
            "I, Paul, an apostle of the Christian faith , and a Christian , published a book on religious faith and religion in Christian literature , called The Christian in\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "KmPQnNmfukFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = \"And Jesus, moved with compassion,\"\n",
        "N_WORDS = 40\n",
        "N_SENTENCES = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "scrolled": true,
        "id": "9Qr713SSukFW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "99a34ccc-cd02-4a29-b60d-38941410fe62"
      },
      "source": [
        "print(\"\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "And Jesus, moved with compassion, first appeared on Late Night with Paul Hunter , on May 29 , March 20 , May 29 , May 20 , March 18 , May her final day of\n",
            "And Jesus, moved with compassion, was released on US - United Nations Special Protection Agency , and continues to be an important source of evidence that Jesus Christ was accused of supporting the Roman Emperor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "0jYCJj2lukFW",
        "colab_type": "text"
      },
      "source": [
        "Lowering `temperature` will make the texts less randomized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "90GClsPBukFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#doc(LanguageLearner.predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "WRS1PxK6ukFY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "17f76c7d-c25c-458d-8452-3cb2b419b8a8"
      },
      "source": [
        "print(\"\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.10) for _ in range(N_SENTENCES)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "And Jesus, moved with compassion, and Jesus Christ , Jesus Christ , Jesus Christ , Jesus Christ , Jesus Christ , Jesus Christ , Jesus Christ , Jesus Christ\n",
            "And Jesus, moved with compassion, and Jesus Christ , Jesus Christ , Jesus Christ , Jesus Christ , Jesus Christ , Jesus Christ , Jesus Christ , Jesus Christ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53VzrpA8ukFa",
        "colab_type": "text"
      },
      "source": [
        "### Training the language model (run first time - otherwise go to load saved weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5O59TRgukFa",
        "colab_type": "text"
      },
      "source": [
        "Now, we want to choose a good learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQcHct32ukFe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "8e77985f-7ebc-464c-9341-3a186cb14b7c"
      },
      "source": [
        "learn_lm.lr_find()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='99' class='' max='7853' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      1.26% [99/7853 00:28<37:49 11.0288]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hErUGSD8ukFf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "db1e4527-d2df-490e-fbd3-6319ad808c83"
      },
      "source": [
        "learn_lm.recorder.plot(skip_end=15)\n",
        "logwriter.append_row([getloggerdt(),'learning rate created'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1RyYJaX1ysSAo4JpXhbRVcrRm1UGV3oUI7SGLg1rwzUs',\n",
              " 'tableRange': 'Sheet1!A1:B5',\n",
              " 'updates': {'spreadsheetId': '1RyYJaX1ysSAo4JpXhbRVcrRm1UGV3oUI7SGLg1rwzUs',\n",
              "  'updatedCells': 2,\n",
              "  'updatedColumns': 2,\n",
              "  'updatedRange': 'Sheet1!A6:B6',\n",
              "  'updatedRows': 1}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXe5cmoP2E8Y",
        "colab_type": "text"
      },
      "source": [
        "You want to choose a learning rate that is in the middle of slope BEFORE it increases again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJfQ6RRwukFj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "0f9a4ea4-8d69-4ea6-fd01-a8f62a4a9538"
      },
      "source": [
        "#set the learning rate from above here\n",
        "lr = 1e-2\n",
        "lr *= bs/48\n",
        "logwriter.append_row([getloggerdt(),'learning rate set to '+str(lr)])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1RyYJaX1ysSAo4JpXhbRVcrRm1UGV3oUI7SGLg1rwzUs',\n",
              " 'tableRange': 'Sheet1!A1:B6',\n",
              " 'updates': {'spreadsheetId': '1RyYJaX1ysSAo4JpXhbRVcrRm1UGV3oUI7SGLg1rwzUs',\n",
              "  'updatedCells': 2,\n",
              "  'updatedColumns': 2,\n",
              "  'updatedRange': 'Sheet1!A7:B7',\n",
              "  'updatedRows': 1}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwkSwW1DukFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_lm.to_fp16();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIXNYl_FukFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "e235e29a-4819-4b2e-d2a8-8f27636e960d"
      },
      "source": [
        "#This trains the top layer of the language model once\n",
        "learn_lm.fit_one_cycle(1, lr*10, moms=(0.8,0.7),callbacks=[SaveModelCallback(learn_lm, every='epoch',monitor='accuracy', name='saved_net'+trans)])\n",
        "logwriter.append_row([getloggerdt(),'top layer of model trained'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.672422</td>\n",
              "      <td>4.428312</td>\n",
              "      <td>0.303565</td>\n",
              "      <td>52:37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1RyYJaX1ysSAo4JpXhbRVcrRm1UGV3oUI7SGLg1rwzUs',\n",
              " 'tableRange': 'Sheet1!A1:B7',\n",
              " 'updates': {'spreadsheetId': '1RyYJaX1ysSAo4JpXhbRVcrRm1UGV3oUI7SGLg1rwzUs',\n",
              "  'updatedCells': 2,\n",
              "  'updatedColumns': 2,\n",
              "  'updatedRange': 'Sheet1!A8:B8',\n",
              "  'updatedRows': 1}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HbM9yEhukFn",
        "colab_type": "text"
      },
      "source": [
        "Since this is relatively slow to train, we will save our weights:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FWA9somukFn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "58c8cab4-e8a9-4402-b863-6999632369bc"
      },
      "source": [
        "learn_lm.save('fit_1'+trans)\n",
        "logwriter.append_row([getloggerdt(),'top layer of model saved as fit_1'+trans])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1RyYJaX1ysSAo4JpXhbRVcrRm1UGV3oUI7SGLg1rwzUs',\n",
              " 'tableRange': 'Sheet1!A1:B8',\n",
              " 'updates': {'spreadsheetId': '1RyYJaX1ysSAo4JpXhbRVcrRm1UGV3oUI7SGLg1rwzUs',\n",
              "  'updatedCells': 2,\n",
              "  'updatedColumns': 2,\n",
              "  'updatedRange': 'Sheet1!A9:B9',\n",
              "  'updatedRows': 1}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZVMwmh5ukFq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cd62e879-7c19-4508-97d3-d72feecb6765"
      },
      "source": [
        "learn_lm.path"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/drive/My Drive/AI & Tech Research/Religion of GPT2')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT0YMx2QukFx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c300635a-9568-4e21-87f3-c1bc80389214"
      },
      "source": [
        "learn_lm.path=Path(\"/content/drive/My Drive/AI & Tech Research/Religion of GPT2/fastai/\")\n",
        "print(learn_lm.path)\n",
        "print(trans)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/AI & Tech Research/Religion of GPT2/fastai\n",
            "wikipedia_relwcat - wikipedia_relwcat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_68xtthukFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_lm.load('fit_1'+trans);"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7YBlgCuukFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#set this learning rate to the same thing (you can play with it if you want)\n",
        "lr = 1e-3\n",
        "lr *= bs/48"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0C8yXY4AukF0",
        "colab_type": "text"
      },
      "source": [
        "To complete the fine-tuning, we can then unfreeze and launch a new training.<br> This will train the entire model 10 times. It will save the model each time just in case the system crashes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsowSb87ukF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_lm.unfreeze()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "K-Jgbh1zukF3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "7d46f552-dce4-472e-b05c-2e88fe6dea12"
      },
      "source": [
        "learn_lm.fit_one_cycle(10, lr, moms=(0.8,0.7),callbacks=[SaveModelCallback(learn_lm, every='epoch',monitor='accuracy', name='10saved_net'+trans)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='4' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      40.00% [4/10 3:55:31<5:53:17]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.756750</td>\n",
              "      <td>3.679063</td>\n",
              "      <td>0.372557</td>\n",
              "      <td>58:46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.680443</td>\n",
              "      <td>3.553093</td>\n",
              "      <td>0.381767</td>\n",
              "      <td>58:53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.509700</td>\n",
              "      <td>3.469995</td>\n",
              "      <td>0.387234</td>\n",
              "      <td>58:51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.454278</td>\n",
              "      <td>3.370074</td>\n",
              "      <td>0.395507</td>\n",
              "      <td>58:52</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='6561' class='' max='7853' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      83.55% [6561/7853 36:04<07:06 3.4018]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlIo2rhTs96_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "c2e9e94e-5185-4576-c69e-0737cffd1562"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Jun 26 17:37:40 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P0    26W /  75W |   6455MiB /  7611MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRT3r-Znh7gO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 931
        },
        "outputId": "ee6e2d92-f338-431f-f625-137358a42d30"
      },
      "source": [
        "#restart if interrupted\n",
        "restart_ep=4\n",
        "learn_lm.fit_one_cycle(10,lr, moms=(0.8,0.7), start_epoch=restart_ep, callbacks=[SaveModelCallback(learn_lm, every='epoch',monitor='accuracy', name='10saved_net'+trans)])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 10saved_netwikipedia_relwcat - wikipedia_relwcat_3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/6 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='7853' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/7853 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-66f600d11302>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#restart if interrupted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrestart_ep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlearn_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrestart_ep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSaveModelCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn_lm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'10saved_net'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     21\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     22\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m def fit_fc(learn:Learner, tot_epochs:int=1, lr:float=defaults.lr,  moms:Tuple[float,float]=(0.95,0.85), start_pct:float=0.72,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.50 GiB (GPU 0; 7.43 GiB total capacity; 5.63 GiB already allocated; 1.13 GiB free; 5.78 GiB reserved in total by PyTorch) (malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:289)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7f96d5a02536 in /usr/local/lib/python3.6/dist-packages/torch/lib/libc10.so)\nframe #1: <unknown function> + 0x1cf1e (0x7f96d5c4bf1e in /usr/local/lib/python3.6/dist-packages/torch/lib/libc10_cuda.so)\nframe #2: <unknown function> + 0x1df9e (0x7f96d5c4cf9e in /usr/local/lib/python3.6/dist-packages/torch/lib/libc10_cuda.so)\nframe #3: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x135 (0x7f96d87f3475 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\nframe #4: <unknown function> + 0xf8135b (0x7f96d6ddf35b in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\nframe #5: <unknown function> + 0xfcac47 (0x7f96d6e28c47 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\nframe #6: <unknown function> + 0x1073c49 (0x7f970e987c49 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #7: <unknown function> + 0x1073f87 (0x7f970e987f87 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #8: <unknown function> + 0xe1ff1e (0x7f970e733f1e in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #9: at::native::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x9e0 (0x7f970e73a810 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #10: <unknown function> + 0x1132be1 (0x7f970ea46be1 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #11: <unknown function> + 0x1185ee3 (0x7f970ea99ee3 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #12: <unknown function> + 0x28c2f52 (0x7f96d8720f52 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\nframe #13: at::Tensor at::native::(anonymous namespace)::host_softmax_backward<at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue, true>(at::Tensor const&, at::Tensor const&, long, bool) + 0xb9 (0x7f96d8735969 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\nframe #14: at::native::log_softmax_backward_cuda(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x99 (0x7f96d87216e9 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\nframe #15: <unknown function> + 0xf8bfe0 (0x7f96d6de9fe0 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\nframe #16: <unknown function> + 0x10c4396 (0x7f970e9d8396 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #17: <unknown function> + 0x2ca977c (0x7f97105bd77c in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #18: <unknown function> + 0x10c4396 (0x7f970e9d8396 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #19: torch::autograd::generated::LogSoftmaxBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1c9 (0x7f97101b9859 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #20: <unknown function> + 0x2d89705 (0x7f971069d705 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #21: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7f971069aa03 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #22: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f971069b7e2 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #23: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f9710693e59 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #24: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7f971cfdb488 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_python.so)\nframe #25: <unknown function> + 0xbd6df (0x7f9740f866df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\nframe #26: <unknown function> + 0x76db (0x7f97420686db in /lib/x86_64-linux-gnu/libpthread.so.0)\nframe #27: clone + 0x3f (0x7f97423a188f in /lib/x86_64-linux-gnu/libc.so.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCDmoEzgukF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_lm.save('fine_tuned_'+trans)\n",
        "logwriter.append_row([loggerdt(),'fine tuned model save as fine_tuned_'+trans])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChuK42ArukF5",
        "colab_type": "text"
      },
      "source": [
        "We have to save not just the model but also it's encoder, the part that's responsible for creating and updating the hidden state. For the next part, we don't care about the part that tries to guess the next word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLqiE6cHukF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_lm.save_encoder('fine_tuned_enc_'+trans)\n",
        "logwriter.append_row([getloggerdt,'fine_tuned encoder saved as fine_tuned_enc_'+trans])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "AoB3C6JhukF7",
        "colab_type": "text"
      },
      "source": [
        "### Loading our saved weights (must run)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "G8gnEjryukF8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2cabced8-89e7-43fe-8355-84a033da1ff7"
      },
      "source": [
        "learn_lm.load('fine_tuned_'+trans);\n",
        "learn_lm.path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/drive/My Drive/testai')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxkvAQ5LacHg",
        "colab_type": "text"
      },
      "source": [
        "#### Encoder Example (Can Skip)###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "leIvZe-pukF9",
        "colab_type": "text"
      },
      "source": [
        "Now that we've trained our model, different representations have been learned for the words that were in IMDB but not wiki (remember that at the beginning we had initialized them all to the same thing):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "v4jWdNO_ukF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc = learn_lm.model[0].encoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "hpzpoH2bukF-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "4276b9f2-379a-46f8-857f-66f908892eea"
      },
      "source": [
        "np.allclose(enc.weight[vocab.stoi[unique_bible_word1], :], \n",
        "            enc.weight[vocab.stoi[unique_bible_words2], :])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-f9e8b9a98eb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m np.allclose(enc.weight[vocab.stoi[unique_bible_word1], :], \n\u001b[0m\u001b[1;32m      2\u001b[0m             enc.weight[vocab.stoi[unique_bible_words2], :])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vocab' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "0XJcsZP0ukF_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "77591113-8868-47a5-e912-f9cf7bff9dcc"
      },
      "source": [
        "np.allclose(enc.weight[vocab.stoi[unique_bible_word1], :], new_word_vec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-11525bd38c5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munique_bible_word1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_word_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'vocab' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "gVBfdshWukGA",
        "colab_type": "text"
      },
      "source": [
        "#### More generated Bible passages (can skip)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "qav-oxqmukGA",
        "colab_type": "text"
      },
      "source": [
        "How good is our model? Well let's try to see what it predicts after a few given words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "aviZVUZ_ukGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = \"and Jesus said\"\n",
        "N_WORDS = 40\n",
        "N_SENTENCES = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "p38T6yuhukGC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "0d6f23ca-8d7b-4533-f8db-27fc0d7b03d9"
      },
      "source": [
        "print(\"\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "and Jesus said to him , “ i am He . ” And Jesus * said to him , “ Follow Me . ” xxbos Now the word of the Lord came to me saying ,\n",
            "and Jesus said to them , “ You are ruby , or who are you , but they must walk in the darkness ? You have no regard for those who hate Me . xxbos For indeed in this\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "qw2A6oSEukGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = \"I, Paul, an apostle\"\n",
        "N_WORDS = 30\n",
        "N_SENTENCES = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "jV3ZT3H8ukGF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2094317a-1c67-4ec9-92e6-36fa9693f6de"
      },
      "source": [
        "print(\"\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I, Paul, an apostle of Christ Jesus by the will of God , the Lord God of hosts , who is Christ , the church and the faith\n",
            "I, Paul, an apostle of Christ Jesus by the will of God , who is called by Christ Jesus Christ ; xxbos He said , “\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "im4Au3cWukGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = \"And Jesus, moved with compassion,\"\n",
        "N_WORDS = 40\n",
        "N_SENTENCES = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "hNTDCeZbukGI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "7479be06-ba11-41cf-c3f9-f42e89aba2fe"
      },
      "source": [
        "print(\"\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "And Jesus, moved with compassion, * said to them , “ Why do you still believe ? ” xxbos Into the first of all your fruits you shall shall give it to the priest , for it is a holy thing to the\n",
            "And Jesus, moved with compassion, * said to them , “ Keep watch with the chief priests and bind them to keep My charge . xxbos Beside the border of Naphtali , from the east side to the west side ,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-VbDxuxukGI",
        "colab_type": "text"
      },
      "source": [
        "### Classifier Setup (Run first time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDHx393UukGJ",
        "colab_type": "text"
      },
      "source": [
        "Now, we'll create a new data object that only grabs the labelled data and keeps those labels. Again, this line takes a bit of time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPHgHa37cMsE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logwriter.append_row([getloggerdt(),'starting classifier setup'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwHaGRNWukGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs=48"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2Bn7T4PukGL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "96ce0299-fb6a-4ffa-e0b1-726ee2c5ed51"
      },
      "source": [
        "#create test set from pandas\n",
        "df_copy=df.copy()\n",
        "print('The number of verses in the whole translation, columns=',df_copy.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of verses in the whole translation, columns= (31103, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kp9JvM3dukGN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9318743d-ae93-476a-9cbe-f06936644778"
      },
      "source": [
        "#Leave out the stuff that we'll test on (we set classifier to blank)\n",
        "is_testable=df_copy['classifier']!=''\n",
        "df_testable=df_copy[is_testable]\n",
        "print('the number of verses that we will train on, colums=',df_testable.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the number of verses that we will train on, colums= (30261, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mb3Jdc8EukGO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "355ec6d5-6885-4ada-dc83-be4694fc73a8"
      },
      "source": [
        "df_testable.groupby('classifier').agg('count')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Version_Full_Name</th>\n",
              "      <th>Version_Abbreviation</th>\n",
              "      <th>Book</th>\n",
              "      <th>Chapter</th>\n",
              "      <th>Verse_Number</th>\n",
              "      <th>Verse_Text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>classifier</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Non-Paul</th>\n",
              "      <td>28767</td>\n",
              "      <td>28767</td>\n",
              "      <td>28767</td>\n",
              "      <td>28767</td>\n",
              "      <td>28767</td>\n",
              "      <td>28767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Paul</th>\n",
              "      <td>1494</td>\n",
              "      <td>1494</td>\n",
              "      <td>1494</td>\n",
              "      <td>1494</td>\n",
              "      <td>1494</td>\n",
              "      <td>1494</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Version_Full_Name  Version_Abbreviation  ...  Verse_Number  Verse_Text\n",
              "classifier                                           ...                          \n",
              "Non-Paul                28767                 28767  ...         28767       28767\n",
              "Paul                     1494                  1494  ...          1494        1494\n",
              "\n",
              "[2 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QvxaW6XukGO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "8787da39-48e4-4448-8394-1364b6b6177c"
      },
      "source": [
        "df_copy.groupby('classifier').agg('count')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Version_Full_Name</th>\n",
              "      <th>Version_Abbreviation</th>\n",
              "      <th>Book</th>\n",
              "      <th>Chapter</th>\n",
              "      <th>Verse_Number</th>\n",
              "      <th>Verse_Text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>classifier</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>842</td>\n",
              "      <td>842</td>\n",
              "      <td>842</td>\n",
              "      <td>842</td>\n",
              "      <td>842</td>\n",
              "      <td>842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Non-Paul</th>\n",
              "      <td>28767</td>\n",
              "      <td>28767</td>\n",
              "      <td>28767</td>\n",
              "      <td>28767</td>\n",
              "      <td>28767</td>\n",
              "      <td>28767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Paul</th>\n",
              "      <td>1494</td>\n",
              "      <td>1494</td>\n",
              "      <td>1494</td>\n",
              "      <td>1494</td>\n",
              "      <td>1494</td>\n",
              "      <td>1494</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Version_Full_Name  Version_Abbreviation  ...  Verse_Number  Verse_Text\n",
              "classifier                                           ...                          \n",
              "                          842                   842  ...           842         842\n",
              "Non-Paul                28767                 28767  ...         28767       28767\n",
              "Paul                     1494                  1494  ...          1494        1494\n",
              "\n",
              "[3 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAxnDyrDukGP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create a training set from the Paul material\n",
        "df_sel_paul=df_copy.loc[df_copy['classifier'] == 'Paul']\n",
        "df_sel_paul.head()\n",
        "df_sample_paul=df_sel_paul.sample(frac=0.80, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9frw6FFkukGQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9f9cfc5-736e-4fa2-9894-4dfaf3dd3c2b"
      },
      "source": [
        "print('the verses in the Pauline training set (80%)=',df_sample_paul.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the verses in the Pauline training set (80%)= (1195, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2QYE2FcukGR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "01ed6736-e02c-4fa6-d16f-915b16b22576"
      },
      "source": [
        "#create a training set from the nonPaul material\n",
        "df_sel_nonpaul=df_copy.loc[df_copy['classifier']=='Non-Paul']\n",
        "df_sample_nonpaul=df_sel_nonpaul.sample(frac=0.80, random_state=0)\n",
        "print('the verses in the non-Pauline training set (80%)=',df_sample_nonpaul.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the verses in the non-Pauline training set (80%)= (23014, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p8koF-qukGS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a07cde4-62d8-407f-d4cf-a0c988ff01a7"
      },
      "source": [
        "#append Paul training and nonPaul training sets\n",
        "df_train=pd.concat([df_sample_paul,df_sample_nonpaul])\n",
        "print('combined training sets (Pauline/non-pauline)=',df_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "combined training sets (Pauline/non-pauline)= (24209, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItPk9g_KukGT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89a3432a-a440-4009-b39a-27ad8ff81113"
      },
      "source": [
        "# get usued record from paul set for test set\n",
        "paul_test=df_sel_paul.drop(df_sample_paul.index)\n",
        "print('the testing set for Pauline material=',paul_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the testing set for Pauline material= (299, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43XUZno0ukGT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74eb3363-2354-4d60-cb6d-6b431cc056be"
      },
      "source": [
        "#get unused records for test set\n",
        "nonpaul_test=df_sel_nonpaul.drop(df_sample_nonpaul.index)\n",
        "print('the testing set for Non-Pauline material=',nonpaul_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the testing set for Non-Pauline material= (5753, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0XS1_hAukGX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ffe8588e-8441-43ad-a9bc-bc89657667da"
      },
      "source": [
        "#append paul and nonpaul test sets\n",
        "df_test=pd.concat([paul_test,nonpaul_test])\n",
        "print('combined testing sets=',df_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "combined testing sets= (6052, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYHH4IbLukGX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "22872f33-dd00-46a0-9081-d5c049f27b09"
      },
      "source": [
        "df_test.groupby(['classifier']).head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Version_Full_Name</th>\n",
              "      <th>Version_Abbreviation</th>\n",
              "      <th>Book</th>\n",
              "      <th>Chapter</th>\n",
              "      <th>Verse_Number</th>\n",
              "      <th>Verse_Text</th>\n",
              "      <th>classifier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27942</th>\n",
              "      <td>New American Standard Bible</td>\n",
              "      <td>NASB</td>\n",
              "      <td>Romans</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>that is, that I may be encouraged together wit...</td>\n",
              "      <td>Paul</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27954</th>\n",
              "      <td>New American Standard Bible</td>\n",
              "      <td>NASB</td>\n",
              "      <td>Romans</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>Therefore God gave them over in the lusts of t...</td>\n",
              "      <td>Paul</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27955</th>\n",
              "      <td>New American Standard Bible</td>\n",
              "      <td>NASB</td>\n",
              "      <td>Romans</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>For they exchanged the truth of God for a lie,...</td>\n",
              "      <td>Paul</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>New American Standard Bible</td>\n",
              "      <td>NASB</td>\n",
              "      <td>Genesis</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>Then God said, “Let the earth sprout vegetatio...</td>\n",
              "      <td>Non-Paul</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>New American Standard Bible</td>\n",
              "      <td>NASB</td>\n",
              "      <td>Genesis</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>Then God said, “Let there be lights in the exp...</td>\n",
              "      <td>Non-Paul</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>New American Standard Bible</td>\n",
              "      <td>NASB</td>\n",
              "      <td>Genesis</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>Then God said, “Let the waters teem with swarm...</td>\n",
              "      <td>Non-Paul</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Version_Full_Name  ... classifier\n",
              "27942  New American Standard Bible  ...       Paul\n",
              "27954  New American Standard Bible  ...       Paul\n",
              "27955  New American Standard Bible  ...       Paul\n",
              "10     New American Standard Bible  ...   Non-Paul\n",
              "13     New American Standard Bible  ...   Non-Paul\n",
              "19     New American Standard Bible  ...   Non-Paul\n",
              "\n",
              "[6 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvxO8stPukGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create the classifier data loader using the test and training sets\n",
        "data_clas=TextClasDataBunch.from_df(path, train_df=df_train, valid_df=df_test, text_cols='Verse_Text', \n",
        "                                    label_cols='classifier',vocab=data_lm.vocab, bs=bs, num_workers=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3irW_BbukGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data_clas = (TextList.from_folder(path, vocab=data_lm.vocab)\n",
        "             #grab all the text files in path#\n",
        "#             .split_by_folder(valid='test')\n",
        "             #split by train and valid folder (that only keeps 'train' and 'test' so no need to filter)\n",
        "#             .label_from_folder(classes=['neg', 'pos'])\n",
        "             #label them all with their folders\n",
        "#             .databunch(bs=bs, num_workers=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APOmqhBsPSnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_clas.path=paulpath"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdwckSVaukGa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b7fd10f-c15c-4c08-b408-308ecca3eda9"
      },
      "source": [
        "#save the classifier data loader\n",
        "class_name='bible_textlist_class_'+trans\n",
        "data_clas.save(class_name)\n",
        "data_clas.path\n",
        "logwriter.append_row([getloggerdt(),'classifier data loader created as bible_textlist_class_'+trans])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/drive/My Drive/testai')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alNcVPmkukGa",
        "colab_type": "text"
      },
      "source": [
        "### Load Classifier (must run)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn7GDLcyukGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load the classifier data loader\n",
        "logwriter.append_row([getloggerdt(),'starting classifier loading'])\n",
        "\n",
        "data_clas = load_data(paulpath,'bible_textlist_class_'+trans, bs=bs, num_workers=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vaJRwMrukGd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "31b6f144-fcdf-4bdd-bf9b-8b955a33a4bf"
      },
      "source": [
        "#create a learner for the classifere, add  the data loader to the pre-trained model\n",
        "learn_c = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.3) #.to_fp16()\n",
        "learn_c.path=paulpath\n",
        "learn_c.load_encoder('fine_tuned_enc'+trans)\n",
        "logwriter.append_row([getloggerdt(),'classifier learner created as learn_c'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (24209 items)\n",
              "x: TextList\n",
              "xxbos xxmaj now if xxmaj christ is preached , that xxmaj he has been raised from the dead , how do some among you say that there is no resurrection of the dead ?,xxbos xxmaj you are looking at things as they are outwardly . xxmaj if anyone is confident in himself that he is xxmaj christ ’s , let him consider this again within himself , that just as he is xxmaj christ ’s , so also are we .,xxbos xxmaj for if we believe that xxmaj jesus died and rose again , even so xxmaj god will bring with xxmaj him those who have fallen asleep in xxmaj jesus .,xxbos xxmaj you who boast in the xxmaj law , through your breaking the xxmaj law , do you dishonor xxmaj god ?,xxbos xxmaj after that xxmaj he appeared to more than five hundred brethren at one time , most of whom remain until now , but some have fallen asleep ;\n",
              "y: CategoryList\n",
              "Paul,Paul,Paul,Paul,Paul\n",
              "Path: /content/drive/My Drive/testai/DigitialJesus/Courtney_s Work - Summer2019/BibleGateway;\n",
              "\n",
              "Valid: LabelList (6052 items)\n",
              "x: TextList\n",
              "xxbos that is , that i may be encouraged together with you while among you , each of us by the other ’s faith , both yours and mine .,xxbos xxmaj therefore xxmaj god gave them over in the lusts of their hearts to impurity , so that their bodies would be dishonored among them .,xxbos xxmaj for they exchanged the truth of xxmaj god for a lie , and worshiped and served the creature rather than the xxmaj creator , who is blessed forever . xxmaj amen .,xxbos xxmaj for this reason xxmaj god gave them over to xxunk passions ; for their women exchanged the natural function for that which is xxunk ,,xxbos being filled with all unrighteousness , wickedness , greed , evil ; full of envy , murder , strife , deceit , malice ; they are gossips ,\n",
              "y: CategoryList\n",
              "Paul,Paul,Paul,Paul,Paul\n",
              "Path: /content/drive/My Drive/testai/DigitialJesus/Courtney_s Work - Summer2019/BibleGateway;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(9776, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(9776, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.12, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7faaac5e0d90>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content/drive/My Drive/testai'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (24209 items)\n",
              "x: TextList\n",
              "xxbos xxmaj now if xxmaj christ is preached , that xxmaj he has been raised from the dead , how do some among you say that there is no resurrection of the dead ?,xxbos xxmaj you are looking at things as they are outwardly . xxmaj if anyone is confident in himself that he is xxmaj christ ’s , let him consider this again within himself , that just as he is xxmaj christ ’s , so also are we .,xxbos xxmaj for if we believe that xxmaj jesus died and rose again , even so xxmaj god will bring with xxmaj him those who have fallen asleep in xxmaj jesus .,xxbos xxmaj you who boast in the xxmaj law , through your breaking the xxmaj law , do you dishonor xxmaj god ?,xxbos xxmaj after that xxmaj he appeared to more than five hundred brethren at one time , most of whom remain until now , but some have fallen asleep ;\n",
              "y: CategoryList\n",
              "Paul,Paul,Paul,Paul,Paul\n",
              "Path: /content/drive/My Drive/testai/DigitialJesus/Courtney_s Work - Summer2019/BibleGateway;\n",
              "\n",
              "Valid: LabelList (6052 items)\n",
              "x: TextList\n",
              "xxbos that is , that i may be encouraged together with you while among you , each of us by the other ’s faith , both yours and mine .,xxbos xxmaj therefore xxmaj god gave them over in the lusts of their hearts to impurity , so that their bodies would be dishonored among them .,xxbos xxmaj for they exchanged the truth of xxmaj god for a lie , and worshiped and served the creature rather than the xxmaj creator , who is blessed forever . xxmaj amen .,xxbos xxmaj for this reason xxmaj god gave them over to xxunk passions ; for their women exchanged the natural function for that which is xxunk ,,xxbos being filled with all unrighteousness , wickedness , greed , evil ; full of envy , murder , strife , deceit , malice ; they are gossips ,\n",
              "y: CategoryList\n",
              "Paul,Paul,Paul,Paul,Paul\n",
              "Path: /content/drive/My Drive/testai/DigitialJesus/Courtney_s Work - Summer2019/BibleGateway;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(9776, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(9776, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.12, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7faaac5e0d90>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content/drive/My Drive/testai'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(9776, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(9776, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.12, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(9776, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(9776, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.12, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmQEoykMDfay",
        "colab_type": "text"
      },
      "source": [
        "### Train Classifier (if already trained, can skip)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFckjWv1ukGb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e526b15-b4ba-4003-c0e4-bc5b2f539481"
      },
      "source": [
        "len(data_clas.vocab.itos) == len(data_lm.vocab.itos)\n",
        "logwriter.append_row([getloggerdt(),'starting classifier training'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTrSDGEaukGc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "ee06d043-052b-498f-eda6-f3a9fcb9d4bf"
      },
      "source": [
        "data_clas.show_batch()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj so the king ’s scribes were called at that time in the third month ( that is , the month xxmaj xxunk ) , on the twenty - third day ; and it was written according to all that xxmaj mordecai commanded to the xxmaj jews , the satraps , the governors and the princes of the provinces which extended from xxmaj india to xxmaj ethiopia , 127</td>\n",
              "      <td>Non-Paul</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj now xxmaj elisha was sitting in his house , and the elders were sitting with him . xxmaj and the king sent a man from his presence ; but before the messenger came to him , he said to the elders , “ xxmaj do you see how this son of a murderer has sent to take away my head ? xxmaj look , when the messenger comes</td>\n",
              "      <td>Non-Paul</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj thus says the xxmaj lord , “ xxmaj the products of xxmaj egypt and the merchandise of xxmaj cush xxmaj and the xxmaj sabeans , men of stature , xxmaj will come over to you and will be yours ; xxmaj they will walk behind you , they will come over in chains xxmaj and will bow down to you ; xxmaj they will make supplication to you</td>\n",
              "      <td>Non-Paul</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj and i will take away the remnant of xxmaj judah who have set their mind on entering the land of xxmaj egypt to reside there , and they will all meet their end in the land of xxmaj egypt ; they will fall by the sword and meet their end by famine . xxmaj both small and great will die by the sword and famine ; and they</td>\n",
              "      <td>Non-Paul</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos “ xxmaj therefore , as i live , ” declares the xxmaj lord of hosts , xxmaj the xxmaj god of xxmaj israel , “ xxmaj surely xxmaj moab will be like xxmaj sodom xxmaj and the sons of xxmaj ammon like xxmaj gomorrah — a place possessed by nettles and salt pits , xxmaj and a perpetual desolation . xxmaj the remnant of xxmaj my people will plunder</td>\n",
              "      <td>Non-Paul</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BN5awasukGd",
        "colab_type": "text"
      },
      "source": [
        "We can then create a model to classify those reviews and load the encoder we saved before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUlto2c1ukGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_c.freeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsodN_m0dPLE",
        "colab_type": "text"
      },
      "source": [
        "Find the learning rate. The learning rate should be in the middle of the downard slope. change the lr variable if necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExDR9lbyukGe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "edc7f156-fc1c-43fc-cf99-ebcb24e87969"
      },
      "source": [
        "learn_c.lr_find()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKrvUGelukGf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "dc8ecb5a-19f0-4275-965d-011346572f98"
      },
      "source": [
        "learn_c.recorder.plot()\n",
        "logwriter.append_row([getloggerdt(),'plotting classifier learning rate'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w8TMcNN4vv7bgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "SIJ8v1RJukGg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "b42f16be-82ba-4135-8b9b-08c1840567d6"
      },
      "source": [
        "lr=1e-2\n",
        "logwriter.append_row([getloggerdt(),'classifier learning rate='+str(lr)])\n",
        "learn_c.fit_one_cycle(1, lr, moms=(0.8,0.7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.118499</td>\n",
              "      <td>0.114143</td>\n",
              "      <td>0.957018</td>\n",
              "      <td>00:49</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrydBz_zukGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_c.save(trans+'_first')\n",
        "logwriter.append_row([getloggerdt(),'classifier top layer training saved as '+trans+\"_first\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne6vmHz6ukGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_c.load(trans+'_first');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMbFOeKmukGj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "f2ca7235-3752-42fd-ce96-e911c25c275b"
      },
      "source": [
        "logwriter.append_row([getloggerdt(),'Unfreezing top 3 layers of classifier and training'])\n",
        "learn_c.freeze_to(-2)\n",
        "learn_c.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.141831</td>\n",
              "      <td>0.144570</td>\n",
              "      <td>0.950736</td>\n",
              "      <td>00:56</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGZQXidGukGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_c.save(trans+'_2nd')\n",
        "logwriter.append_row([getloggerdt(),'classifier top 3 layers training saved as '+trans+\"_2nd\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZOd-Vcvx7eK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_c.load(trans+'_2nd')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRFcTWxrukGk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "929fb113-0db9-4d9a-efda-b55e094b9ce3"
      },
      "source": [
        "logwriter.append_row([getloggerdt(),'Unfreezing top 4 layers of classifier and training'])\n",
        "learn_c.freeze_to(-3)\n",
        "learn_c.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.107132</td>\n",
              "      <td>0.161605</td>\n",
              "      <td>0.950570</td>\n",
              "      <td>01:24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKgjTw_oukGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_c.save(trans+'_3rd')\n",
        "logwriter.append_row([getloggerdt(),'classifier top 3 layers training saved as '+trans+\"_3rd\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cexcFeRSWWxZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0d35269b-4a8a-4d00-f355-b27c37e9a44f"
      },
      "source": [
        "learn_c.load(trans+'_3rd')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (24195 items)\n",
              "x: TextList\n",
              "xxbos xxmaj if there is no resurrection of the dead , then not even xxmaj christ has been raised .,xxbos xxmaj you are judging by appearances . xxmaj if anyone is confident that they belong to xxmaj christ , they should consider again that we belong to xxmaj christ just as much as they do .,xxbos xxmaj for we believe that xxmaj jesus died and rose again , and so we believe that xxmaj god will bring with xxmaj jesus those who have fallen asleep in him .,xxbos xxmaj you who boast in the law , do you dishonor xxmaj god by breaking the law ?,xxbos xxmaj then he appeared to xxmaj james , then to all the apostles ,\n",
              "y: CategoryList\n",
              "Paul,Paul,Paul,Paul,Paul\n",
              "Path: /content/drive/My Drive/AI & Tech Research/PaulAI/DigitialJesus/Courtney_s Work - Summer2019/BibleGateway;\n",
              "\n",
              "Valid: LabelList (6049 items)\n",
              "x: TextList\n",
              "xxbos that is , that you and i may be xxunk encouraged by each other ’s faith .,xxbos xxmaj therefore xxmaj god gave them over in the sinful desires of their hearts to sexual impurity for the xxunk of their bodies with one another .,xxbos xxmaj they exchanged the truth about xxmaj god for a lie , and worshiped and served created things rather than the xxmaj creator — who is forever praised . xxmaj amen .,xxbos xxmaj because of this , xxmaj god gave them over to shameful lusts . xxmaj even their women exchanged natural sexual relations for xxunk ones .,xxbos xxmaj they have become filled with every kind of wickedness , evil , greed and depravity . xxmaj they are full of envy , murder , strife , deceit and malice . xxmaj they are xxunk ,\n",
              "y: CategoryList\n",
              "Paul,Paul,Paul,Paul,Paul\n",
              "Path: /content/drive/My Drive/AI & Tech Research/PaulAI/DigitialJesus/Courtney_s Work - Summer2019/BibleGateway;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(9800, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(9800, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.12, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f8977a638c8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content/drive/My Drive/AI & Tech Research/PaulAI'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (24195 items)\n",
              "x: TextList\n",
              "xxbos xxmaj if there is no resurrection of the dead , then not even xxmaj christ has been raised .,xxbos xxmaj you are judging by appearances . xxmaj if anyone is confident that they belong to xxmaj christ , they should consider again that we belong to xxmaj christ just as much as they do .,xxbos xxmaj for we believe that xxmaj jesus died and rose again , and so we believe that xxmaj god will bring with xxmaj jesus those who have fallen asleep in him .,xxbos xxmaj you who boast in the law , do you dishonor xxmaj god by breaking the law ?,xxbos xxmaj then he appeared to xxmaj james , then to all the apostles ,\n",
              "y: CategoryList\n",
              "Paul,Paul,Paul,Paul,Paul\n",
              "Path: /content/drive/My Drive/AI & Tech Research/PaulAI/DigitialJesus/Courtney_s Work - Summer2019/BibleGateway;\n",
              "\n",
              "Valid: LabelList (6049 items)\n",
              "x: TextList\n",
              "xxbos that is , that you and i may be xxunk encouraged by each other ’s faith .,xxbos xxmaj therefore xxmaj god gave them over in the sinful desires of their hearts to sexual impurity for the xxunk of their bodies with one another .,xxbos xxmaj they exchanged the truth about xxmaj god for a lie , and worshiped and served created things rather than the xxmaj creator — who is forever praised . xxmaj amen .,xxbos xxmaj because of this , xxmaj god gave them over to shameful lusts . xxmaj even their women exchanged natural sexual relations for xxunk ones .,xxbos xxmaj they have become filled with every kind of wickedness , evil , greed and depravity . xxmaj they are full of envy , murder , strife , deceit and malice . xxmaj they are xxunk ,\n",
              "y: CategoryList\n",
              "Paul,Paul,Paul,Paul,Paul\n",
              "Path: /content/drive/My Drive/AI & Tech Research/PaulAI/DigitialJesus/Courtney_s Work - Summer2019/BibleGateway;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(9800, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(9800, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.12, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f8977a638c8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content/drive/My Drive/AI & Tech Research/PaulAI'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(9800, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(9800, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.12, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(9800, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(9800, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.12, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_ZJlZjGdRpN",
        "colab_type": "text"
      },
      "source": [
        "change ep to the number of epochs you wish to run (100 is the default)<br>\n",
        "This will train the entire classifier. It will search for the most accurate model and then save that when execute the save in the next cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WPoOXm_ukGm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "outputId": "c8bfc200-65b2-41a4-a366-91180930b9e9"
      },
      "source": [
        "#ep=100\n",
        "ep=10\n",
        "logwriter.append_row([getloggerdt(),'training entire model for'+str(ep)+' epochs'])\n",
        "learn_c.unfreeze()\n",
        "learn_c.fit_one_cycle(ep, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7),callbacks=[SaveModelCallback(learn_c, every='improvement',monitor='accuracy', name='best_class_'+trans)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.709287</td>\n",
              "      <td>0.643612</td>\n",
              "      <td>0.700595</td>\n",
              "      <td>00:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.328633</td>\n",
              "      <td>0.210170</td>\n",
              "      <td>0.963483</td>\n",
              "      <td>00:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.102644</td>\n",
              "      <td>0.095461</td>\n",
              "      <td>0.970258</td>\n",
              "      <td>00:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.073645</td>\n",
              "      <td>0.079510</td>\n",
              "      <td>0.973067</td>\n",
              "      <td>00:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.053408</td>\n",
              "      <td>0.077108</td>\n",
              "      <td>0.972736</td>\n",
              "      <td>00:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.031336</td>\n",
              "      <td>0.077885</td>\n",
              "      <td>0.974884</td>\n",
              "      <td>00:33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.024560</td>\n",
              "      <td>0.079723</td>\n",
              "      <td>0.974389</td>\n",
              "      <td>00:32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.018090</td>\n",
              "      <td>0.081636</td>\n",
              "      <td>0.975380</td>\n",
              "      <td>00:33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.011516</td>\n",
              "      <td>0.081438</td>\n",
              "      <td>0.976206</td>\n",
              "      <td>00:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.014480</td>\n",
              "      <td>0.083612</td>\n",
              "      <td>0.976867</td>\n",
              "      <td>00:34</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 0 with accuracy value: 0.7005948424339294.\n",
            "Better model found at epoch 1 with accuracy value: 0.9634831547737122.\n",
            "Better model found at epoch 2 with accuracy value: 0.9702577590942383.\n",
            "Better model found at epoch 3 with accuracy value: 0.9730667471885681.\n",
            "Better model found at epoch 5 with accuracy value: 0.9748843312263489.\n",
            "Better model found at epoch 7 with accuracy value: 0.9753800630569458.\n",
            "Better model found at epoch 8 with accuracy value: 0.9762061834335327.\n",
            "Better model found at epoch 9 with accuracy value: 0.976867139339447.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWpJ27VMukGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_c.save('clas_'+trans)\n",
        "logwriter.append_row([getloggerdt(),'best model saved as class_'+trans])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfNI_GauukGn",
        "colab_type": "text"
      },
      "source": [
        "### run predictor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqE5H8IUukGn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "47d25135-66c0-4e74-9323-6d1b4ac97ffe"
      },
      "source": [
        "logwriter.append_row([getloggerdt(),'run predictor'])\n",
        "learn_c.load('clas_'+trans)\n",
        "\n",
        "#learn_c.load('clas'+trans)\n",
        "#learn_c."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (24209 items)\n",
              "x: TextList\n",
              "xxbos xxmaj now if xxmaj christ is preached , that xxmaj he has been raised from the dead , how do some among you say that there is no resurrection of the dead ?,xxbos xxmaj you are looking at things as they are outwardly . xxmaj if anyone is confident in himself that he is xxmaj christ ’s , let him consider this again within himself , that just as he is xxmaj christ ’s , so also are we .,xxbos xxmaj for if we believe that xxmaj jesus died and rose again , even so xxmaj god will bring with xxmaj him those who have fallen asleep in xxmaj jesus .,xxbos xxmaj you who boast in the xxmaj law , through your breaking the xxmaj law , do you dishonor xxmaj god ?,xxbos xxmaj after that xxmaj he appeared to more than five hundred brethren at one time , most of whom remain until now , but some have fallen asleep ;\n",
              "y: CategoryList\n",
              "Paul,Paul,Paul,Paul,Paul\n",
              "Path: /content/drive/My Drive/testai/DigitialJesus/Courtney_s Work - Summer2019/BibleGateway;\n",
              "\n",
              "Valid: LabelList (6052 items)\n",
              "x: TextList\n",
              "xxbos that is , that i may be encouraged together with you while among you , each of us by the other ’s faith , both yours and mine .,xxbos xxmaj therefore xxmaj god gave them over in the lusts of their hearts to impurity , so that their bodies would be dishonored among them .,xxbos xxmaj for they exchanged the truth of xxmaj god for a lie , and worshiped and served the creature rather than the xxmaj creator , who is blessed forever . xxmaj amen .,xxbos xxmaj for this reason xxmaj god gave them over to xxunk passions ; for their women exchanged the natural function for that which is xxunk ,,xxbos being filled with all unrighteousness , wickedness , greed , evil ; full of envy , murder , strife , deceit , malice ; they are gossips ,\n",
              "y: CategoryList\n",
              "Paul,Paul,Paul,Paul,Paul\n",
              "Path: /content/drive/My Drive/testai/DigitialJesus/Courtney_s Work - Summer2019/BibleGateway;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(9776, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(9776, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.12, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7faaac5e0d90>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content/drive/My Drive/testai'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (24209 items)\n",
              "x: TextList\n",
              "xxbos xxmaj now if xxmaj christ is preached , that xxmaj he has been raised from the dead , how do some among you say that there is no resurrection of the dead ?,xxbos xxmaj you are looking at things as they are outwardly . xxmaj if anyone is confident in himself that he is xxmaj christ ’s , let him consider this again within himself , that just as he is xxmaj christ ’s , so also are we .,xxbos xxmaj for if we believe that xxmaj jesus died and rose again , even so xxmaj god will bring with xxmaj him those who have fallen asleep in xxmaj jesus .,xxbos xxmaj you who boast in the xxmaj law , through your breaking the xxmaj law , do you dishonor xxmaj god ?,xxbos xxmaj after that xxmaj he appeared to more than five hundred brethren at one time , most of whom remain until now , but some have fallen asleep ;\n",
              "y: CategoryList\n",
              "Paul,Paul,Paul,Paul,Paul\n",
              "Path: /content/drive/My Drive/testai/DigitialJesus/Courtney_s Work - Summer2019/BibleGateway;\n",
              "\n",
              "Valid: LabelList (6052 items)\n",
              "x: TextList\n",
              "xxbos that is , that i may be encouraged together with you while among you , each of us by the other ’s faith , both yours and mine .,xxbos xxmaj therefore xxmaj god gave them over in the lusts of their hearts to impurity , so that their bodies would be dishonored among them .,xxbos xxmaj for they exchanged the truth of xxmaj god for a lie , and worshiped and served the creature rather than the xxmaj creator , who is blessed forever . xxmaj amen .,xxbos xxmaj for this reason xxmaj god gave them over to xxunk passions ; for their women exchanged the natural function for that which is xxunk ,,xxbos being filled with all unrighteousness , wickedness , greed , evil ; full of envy , murder , strife , deceit , malice ; they are gossips ,\n",
              "y: CategoryList\n",
              "Paul,Paul,Paul,Paul,Paul\n",
              "Path: /content/drive/My Drive/testai/DigitialJesus/Courtney_s Work - Summer2019/BibleGateway;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(9776, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(9776, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.12, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7faaac5e0d90>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content/drive/My Drive/testai'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(9776, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(9776, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.12, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(9776, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(9776, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.12, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnkU398H0Mzj",
        "colab_type": "text"
      },
      "source": [
        "### Change *check* to test a particular book"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gshvSviqukGp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7118d704-77e8-49a6-aa56-5cb4409a0abb"
      },
      "source": [
        "#set predict check\n",
        "check=\"Philemon\"\n",
        "#df_sel_paul=df_copy.loc[df_copy['classifier'] == 'Paul']\n",
        "try:\n",
        "  df_check=df_copy.loc[df_copy['Book']==check]\n",
        "except NameError:\n",
        "  df_copy=df.copy()\n",
        "  df_check=df_copy.loc[df_copy['Book']==check]\n",
        "\n",
        "df_check.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Version_Full_Name</th>\n",
              "      <th>Version_Abbreviation</th>\n",
              "      <th>Book</th>\n",
              "      <th>Chapter</th>\n",
              "      <th>Verse_Number</th>\n",
              "      <th>Verse_Text</th>\n",
              "      <th>classifier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>29939</th>\n",
              "      <td>New American Standard Bible</td>\n",
              "      <td>NASB</td>\n",
              "      <td>Philemon</td>\n",
              "      <td>Philemon</td>\n",
              "      <td>1</td>\n",
              "      <td>Paul, a prisoner of Christ Jesus, and Timothy ...</td>\n",
              "      <td>Paul</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29940</th>\n",
              "      <td>New American Standard Bible</td>\n",
              "      <td>NASB</td>\n",
              "      <td>Philemon</td>\n",
              "      <td>Philemon</td>\n",
              "      <td>2</td>\n",
              "      <td>and to Apphia our sister, and to Archippus our...</td>\n",
              "      <td>Paul</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29941</th>\n",
              "      <td>New American Standard Bible</td>\n",
              "      <td>NASB</td>\n",
              "      <td>Philemon</td>\n",
              "      <td>Philemon</td>\n",
              "      <td>3</td>\n",
              "      <td>Grace to you and peace from God our Father and...</td>\n",
              "      <td>Paul</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29942</th>\n",
              "      <td>New American Standard Bible</td>\n",
              "      <td>NASB</td>\n",
              "      <td>Philemon</td>\n",
              "      <td>Philemon</td>\n",
              "      <td>4</td>\n",
              "      <td>I thank my God always, making mention of you i...</td>\n",
              "      <td>Paul</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29943</th>\n",
              "      <td>New American Standard Bible</td>\n",
              "      <td>NASB</td>\n",
              "      <td>Philemon</td>\n",
              "      <td>Philemon</td>\n",
              "      <td>5</td>\n",
              "      <td>because I hear of your love and of the faith w...</td>\n",
              "      <td>Paul</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Version_Full_Name  ... classifier\n",
              "29939  New American Standard Bible  ...       Paul\n",
              "29940  New American Standard Bible  ...       Paul\n",
              "29941  New American Standard Bible  ...       Paul\n",
              "29942  New American Standard Bible  ...       Paul\n",
              "29943  New American Standard Bible  ...       Paul\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 342
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xy-LzBAukGq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "cf0fbbce-2eaf-4371-d83e-e303909fc558"
      },
      "source": [
        "#interp = TextClassificationInterpretation.from_learner(learn_c) \n",
        "df_predict=pd.DataFrame(columns=['Book','Chapter','Verse','Cat','Non-paul_likelihood','Paul_likelihood'])\n",
        "for index, rows in df_check.iterrows():\n",
        "    pred=learn_c.predict(rows['Verse_Text'])\n",
        "    #print(pred)\n",
        "    #print('cat='+str(pred[0])+' likelihood of non-paul='+str(pred[2][0])+\" likelihood of paul=\"+str(pred[2][1]))\n",
        "    #interp.show_intrinsic_attention(rows['Verse_Text'])\n",
        "    df_predict=df_predict.append({'Book':rows['Book'],'Chapter':rows['Chapter'],'Verse':rows['Verse_Number'],\n",
        "                                 'Cat':str(pred[0]),'Non-paul_likelihood':pred[2][0].item(), 'Paul_likelihood':pred[2][1].item()}, ignore_index=True)\n",
        "logwriter.append_row([getloggerdt(),'ran prediction for '+check])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '15atohUJtoredXMk8Zw-EegqvStM--huxZlpsIhrFVsA',\n",
              " 'tableRange': 'nasb_log!A1:B39',\n",
              " 'updates': {'spreadsheetId': '15atohUJtoredXMk8Zw-EegqvStM--huxZlpsIhrFVsA',\n",
              "  'updatedCells': 2,\n",
              "  'updatedColumns': 2,\n",
              "  'updatedRange': 'nasb_log!A40:B40',\n",
              "  'updatedRows': 1}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 354
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DamHZVz5ukGq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4cd543cb-e33e-495d-f5ce-bd562b915bac"
      },
      "source": [
        "df_predict.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Book</th>\n",
              "      <th>Chapter</th>\n",
              "      <th>Verse</th>\n",
              "      <th>Cat</th>\n",
              "      <th>Non-paul_likelihood</th>\n",
              "      <th>Paul_likelihood</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Philemon</td>\n",
              "      <td>Philemon</td>\n",
              "      <td>1</td>\n",
              "      <td>Paul</td>\n",
              "      <td>0.001846</td>\n",
              "      <td>0.998154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Philemon</td>\n",
              "      <td>Philemon</td>\n",
              "      <td>2</td>\n",
              "      <td>Paul</td>\n",
              "      <td>0.000450</td>\n",
              "      <td>0.999550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Philemon</td>\n",
              "      <td>Philemon</td>\n",
              "      <td>3</td>\n",
              "      <td>Paul</td>\n",
              "      <td>0.001958</td>\n",
              "      <td>0.998042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Philemon</td>\n",
              "      <td>Philemon</td>\n",
              "      <td>4</td>\n",
              "      <td>Paul</td>\n",
              "      <td>0.000149</td>\n",
              "      <td>0.999851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Philemon</td>\n",
              "      <td>Philemon</td>\n",
              "      <td>5</td>\n",
              "      <td>Paul</td>\n",
              "      <td>0.039467</td>\n",
              "      <td>0.960533</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Book   Chapter Verse   Cat  Non-paul_likelihood  Paul_likelihood\n",
              "0  Philemon  Philemon     1  Paul             0.001846         0.998154\n",
              "1  Philemon  Philemon     2  Paul             0.000450         0.999550\n",
              "2  Philemon  Philemon     3  Paul             0.001958         0.998042\n",
              "3  Philemon  Philemon     4  Paul             0.000149         0.999851\n",
              "4  Philemon  Philemon     5  Paul             0.039467         0.960533"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 355
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVK3e9NEukGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "66a36e8f-539d-433c-cc25-f73c1011da1f"
      },
      "source": [
        "mean_res=df_predict.mean(axis=0, numeric_only=True, skipna=True)\n",
        "mean_res"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Non-paul_likelihood    0.014381\n",
              "Paul_likelihood        0.985619\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 356
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpZ-yxDSM-6i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "e2b2aa3d-eba9-496f-fa79-49eae8d9202b"
      },
      "source": [
        "mean_str=mean_res.to_string()\n",
        "print(mean_str)\n",
        "\n",
        "logwriter.append_row([getloggerdt(),'prediction results '+mean_str])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Non-paul_likelihood    0.014381\n",
            "Paul_likelihood        0.985619\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '15atohUJtoredXMk8Zw-EegqvStM--huxZlpsIhrFVsA',\n",
              " 'tableRange': 'nasb_log!A1:B40',\n",
              " 'updates': {'spreadsheetId': '15atohUJtoredXMk8Zw-EegqvStM--huxZlpsIhrFVsA',\n",
              "  'updatedCells': 2,\n",
              "  'updatedColumns': 2,\n",
              "  'updatedRange': 'nasb_log!A41:B41',\n",
              "  'updatedRows': 1}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 357
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZT3bgSjukGs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2311fc8f-612e-43b6-cd77-55d4e3cfb6c0"
      },
      "source": [
        "print('Verse categorization')\n",
        "paul_count=df_predict.groupby('Cat').size()\n",
        "print(paul_count)\n",
        "logwriter.append_row([getloggerdt(),'verse categorization= '+paul_count.to_string()])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Verse categorization\n",
            "Cat\n",
            "Paul    25\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '15atohUJtoredXMk8Zw-EegqvStM--huxZlpsIhrFVsA',\n",
              " 'tableRange': 'nasb_log!A1:B41',\n",
              " 'updates': {'spreadsheetId': '15atohUJtoredXMk8Zw-EegqvStM--huxZlpsIhrFVsA',\n",
              "  'updatedCells': 2,\n",
              "  'updatedColumns': 2,\n",
              "  'updatedRange': 'nasb_log!A42:B42',\n",
              "  'updatedRows': 1}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 358
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "31e6CBZtukGt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "496fffda-2fd1-4940-8a4e-5cbb4e4ec305"
      },
      "source": [
        "#prepare numbers for spreadsheet\n",
        "type(mean_res)\n",
        "mean_res_list=mean_res.to_list()\n",
        "mean_res_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.014381215746107045, 0.9856187772750854]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 359
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLJ-jFdHukGt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be564c03-426b-4a7f-a9d6-2dffc8fcb24a"
      },
      "source": [
        "#create spreadsheet cells\n",
        "out_list=[check]+mean_res.to_list()+paul_count.to_list()\n",
        "out_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Philemon', 0.014381215746107045, 0.9856187772750854, 25]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 360
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKK2UY7MukGu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "bfd151bd-1424-4387-debf-23c9ca6833a5"
      },
      "source": [
        "#post to spreadsheet\n",
        "cell_list=worksheet.range(1,last_col,5,last_col)\n",
        "j=0\n",
        "for cell in cell_list:\n",
        "    cell.value=out_list[j]\n",
        "    j=j+1\n",
        "worksheet.update_cells(cell_list)\n",
        "last_col+=1\n",
        "logwriter.append_row([getloggerdt(),'Posted results to spreadsheet'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-361-e05c9a838526>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcell_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mworksheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_cells\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r-HGcfAVPSf",
        "colab_type": "text"
      },
      "source": [
        "### Model Interpretation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZh7_QZuukGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Run first to create interpreter\n",
        "interp=TextClassificationInterpretation.from_learner(learn_c)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfkKcOaWn7zB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SET VERSE AND CHAPTER\n",
        "chapter=1\n",
        "verse=3\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcXdYaMRVtLL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "65b2abee-7ca4-42fc-9c8f-06e487ccbe5c"
      },
      "source": [
        "df_check=df_check.astype({'Chapter':'int64'})\n",
        "check_text_ser=df_check.loc[(df_check['Verse_Number'] ==verse) & (df_check['Chapter']==chapter) ].Verse_Text\n",
        "check_text=check_text_ser.iloc[0]\n",
        "print(check_text)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Blessed be the God and Father of our Lord Jesus Christ, who has blessed us with every spiritual blessing in the heavenly places in Christ,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BITLZcM0qSa2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_predict.dtypes\n",
        "df_predict=df_predict.astype({'Chapter':'int64'},{'Verse':'int64'})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfHYiEnQlOSI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "5eddaeb8-ebaa-4c50-87d3-2c5bd05797be"
      },
      "source": [
        "import matplotlib.cm as cm\n",
        "\n",
        "print(df_predict.loc[(df_predict['Verse']==verse) & (df_predict['Chapter']==chapter)])\n",
        "\n",
        "interp.show_intrinsic_attention(check_text,cmap=cm.Purples)\n",
        "interp.intrinsic_attention(check_text)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        Book  Chapter Verse   Cat  Non-paul_likelihood  Paul_likelihood\n",
            "2  Ephesians        1     3  Paul             0.036072         0.963928\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"font-family: monospace;\"><span title=\"0.113\" style=\"background-color: rgba(240, 238, 245, 0.5);\">xxbos</span> <span title=\"0.153\" style=\"background-color: rgba(234, 232, 242, 0.5);\">xxmaj</span> <span title=\"0.905\" style=\"background-color: rgba(78, 29, 138, 0.5);\">blessed</span> <span title=\"0.617\" style=\"background-color: rgba(129, 126, 186, 0.5);\">be</span> <span title=\"0.369\" style=\"background-color: rgba(189, 190, 220, 0.5);\">the</span> <span title=\"0.336\" style=\"background-color: rgba(197, 197, 224, 0.5);\">xxmaj</span> <span title=\"0.635\" style=\"background-color: rgba(126, 121, 184, 0.5);\">god</span> <span title=\"0.541\" style=\"background-color: rgba(148, 144, 195, 0.5);\">and</span> <span title=\"0.293\" style=\"background-color: rgba(207, 207, 229, 0.5);\">xxmaj</span> <span title=\"0.736\" style=\"background-color: rgba(108, 85, 165, 0.5);\">father</span> <span title=\"0.418\" style=\"background-color: rgba(177, 176, 212, 0.5);\">of</span> <span title=\"0.634\" style=\"background-color: rgba(126, 121, 184, 0.5);\">our</span> <span title=\"0.337\" style=\"background-color: rgba(197, 197, 224, 0.5);\">xxmaj</span> <span title=\"0.629\" style=\"background-color: rgba(126, 122, 184, 0.5);\">lord</span> <span title=\"0.363\" style=\"background-color: rgba(191, 192, 221, 0.5);\">xxmaj</span> <span title=\"0.776\" style=\"background-color: rgba(101, 72, 158, 0.5);\">jesus</span> <span title=\"0.376\" style=\"background-color: rgba(187, 188, 219, 0.5);\">xxmaj</span> <span title=\"0.653\" style=\"background-color: rgba(122, 114, 180, 0.5);\">christ</span> <span title=\"0.161\" style=\"background-color: rgba(232, 231, 242, 0.5);\">,</span> <span title=\"0.238\" style=\"background-color: rgba(220, 220, 236, 0.5);\">who</span> <span title=\"0.379\" style=\"background-color: rgba(186, 187, 219, 0.5);\">has</span> <span title=\"0.773\" style=\"background-color: rgba(102, 73, 159, 0.5);\">blessed</span> <span title=\"0.641\" style=\"background-color: rgba(124, 118, 182, 0.5);\">us</span> <span title=\"0.373\" style=\"background-color: rgba(188, 189, 220, 0.5);\">with</span> <span title=\"0.370\" style=\"background-color: rgba(189, 190, 220, 0.5);\">every</span> <span title=\"0.558\" style=\"background-color: rgba(144, 140, 193, 0.5);\">spiritual</span> <span title=\"0.707\" style=\"background-color: rgba(113, 96, 171, 0.5);\">blessing</span> <span title=\"0.340\" style=\"background-color: rgba(196, 196, 224, 0.5);\">in</span> <span title=\"0.256\" style=\"background-color: rgba(216, 216, 234, 0.5);\">the</span> <span title=\"0.525\" style=\"background-color: rgba(151, 148, 197, 0.5);\">heavenly</span> <span title=\"0.680\" style=\"background-color: rgba(117, 104, 175, 0.5);\">places</span> <span title=\"0.534\" style=\"background-color: rgba(150, 146, 196, 0.5);\">in</span> <span title=\"0.331\" style=\"background-color: rgba(198, 199, 225, 0.5);\">xxmaj</span> <span title=\"1.000\" style=\"background-color: rgba(63, 0, 125, 0.5);\">christ</span> <span title=\"0.815\" style=\"background-color: rgba(94, 58, 152, 0.5);\">,</span></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Text xxbos xxmaj blessed be the xxmaj god and xxmaj father of our xxmaj lord xxmaj jesus xxmaj christ , who has blessed us with every spiritual blessing in the heavenly places in xxmaj christ ,,\n",
              " tensor([0.1128, 0.1532, 0.9053, 0.6172, 0.3694, 0.3360, 0.6350, 0.5408, 0.2933,\n",
              "         0.7356, 0.4185, 0.6342, 0.3372, 0.6291, 0.3630, 0.7760, 0.3762, 0.6530,\n",
              "         0.1608, 0.2381, 0.3793, 0.7730, 0.6412, 0.3731, 0.3695, 0.5580, 0.7069,\n",
              "         0.3400, 0.2558, 0.5253, 0.6802, 0.5342, 0.3309, 1.0000, 0.8153],\n",
              "        device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 341
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpgiQksen1ah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}