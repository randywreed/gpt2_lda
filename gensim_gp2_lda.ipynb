{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0dSRsRQadJZq"
   },
   "source": [
    "Topic modeling using gensim\n",
    "[from link](https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "!pip install gensim\n",
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2105,
     "status": "ok",
     "timestamp": 1590245062374,
     "user": {
      "displayName": "Randall Reed",
      "photoUrl": "",
      "userId": "15553862248564132325"
     },
     "user_tz": 240
    },
    "id": "EtypATc5dHTi",
    "outputId": "a6b25582-c97c-4e46-f263-9a6fafa8ce18"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10697,
     "status": "ok",
     "timestamp": 1590245106549,
     "user": {
      "displayName": "Randall Reed",
      "photoUrl": "",
      "userId": "15553862248564132325"
     },
     "user_tz": 240
    },
    "id": "iL71RDEpebRc",
    "outputId": "0f5538a9-25d0-462a-d9a8-09790b484a41"
   },
   "outputs": [],
   "source": [
    "#restart the kernel after running this (colab Runtime->Restart Runtime)\n",
    "!pip install --upgrade -q gspread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5594,
     "status": "ok",
     "timestamp": 1590245139371,
     "user": {
      "displayName": "Randall Reed",
      "photoUrl": "",
      "userId": "15553862248564132325"
     },
     "user_tz": 240
    },
    "id": "QjDBGV1ITRGt",
    "outputId": "22d03ec2-54b7-46cd-ce75-20f0651511da"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade wandb\n",
    "!wandb login fcfc2eca6b5d76c9f5532e9ef9d320af69a388ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 674
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7202,
     "status": "ok",
     "timestamp": 1590245149942,
     "user": {
      "displayName": "Randall Reed",
      "photoUrl": "",
      "userId": "15553862248564132325"
     },
     "user_tz": 240
    },
    "id": "LvHAICW4dpsH",
    "outputId": "0469c857-ae25-4807-c197-1ba4f244d5f5"
   },
   "outputs": [],
   "source": [
    "!pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 46285,
     "status": "ok",
     "timestamp": 1590245192498,
     "user": {
      "displayName": "Randall Reed",
      "photoUrl": "",
      "userId": "15553862248564132325"
     },
     "user_tz": 240
    },
    "id": "TxRBemlvebN7",
    "outputId": "1cb0ef31-2a4a-473e-877b-d6de0fbb7427"
   },
   "outputs": [],
   "source": [
    "\n",
    "import gspread\n",
    "'''\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
    "'''\n",
    "gc=gspread.oauth()\n",
    "worksheet = gc.open('Gpt Huggingface results').sheet1\n",
    "\n",
    "# get_all_values gives a list of rows.\n",
    "rows = worksheet.get_all_values()\n",
    "print(rows)\n",
    "\n",
    "# Convert to a DataFrame and render.\n",
    "import pandas as pd\n",
    "df=pd.DataFrame.from_records(rows)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 940,
     "status": "ok",
     "timestamp": 1590247360681,
     "user": {
      "displayName": "Randall Reed",
      "photoUrl": "",
      "userId": "15553862248564132325"
     },
     "user_tz": 240
    },
    "id": "BXMpq5bdfbPp",
    "outputId": "cfbd72ba-132a-4c37-d883-74c0460de8ab"
   },
   "outputs": [],
   "source": [
    "df.columns=[\"prompt\",\"text\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1008,
     "status": "ok",
     "timestamp": 1590247422200,
     "user": {
      "displayName": "Randall Reed",
      "photoUrl": "",
      "userId": "15553862248564132325"
     },
     "user_tz": 240
    },
    "id": "JTRNhGneM5MO",
    "outputId": "0eb21ad8-6819-4bdf-e2c1-882b198e2605"
   },
   "outputs": [],
   "source": [
    "#remove the prompt from text\n",
    "for index,row in df.iterrows():\n",
    "  df.at[index,'text']=row['text'][len(row['prompt']):]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6505,
     "status": "ok",
     "timestamp": 1590247429919,
     "user": {
      "displayName": "Randall Reed",
      "photoUrl": "",
      "userId": "15553862248564132325"
     },
     "user_tz": 240
    },
    "id": "NzU1puS9dfIt",
    "outputId": "c9147821-e4ef-4288-91cd-6cba0d3b2435"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "cohere=[]\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XfqR3F62dmu8"
   },
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kKyShYG3d_o2"
   },
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1988,
     "status": "ok",
     "timestamp": 1590247430783,
     "user": {
      "displayName": "Randall Reed",
      "photoUrl": "",
      "userId": "15553862248564132325"
     },
     "user_tz": 240
    },
    "id": "UqKQRsiELRuf",
    "outputId": "f8c315d5-1d25-4e52-d725-96db116d6e0e"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1244,
     "status": "ok",
     "timestamp": 1590247433261,
     "user": {
      "displayName": "Randall Reed",
      "photoUrl": "",
      "userId": "15553862248564132325"
     },
     "user_tz": 240
    },
    "id": "d0eTxgPqeyqz",
    "outputId": "28d14c40-75ef-4982-8180-0352c7fbbe26"
   },
   "outputs": [],
   "source": [
    "data_words=[]\n",
    "data_words_ret=[]\n",
    "for index,row in df.iterrows():\n",
    "  data=nltk.tokenize.sent_tokenize(row['text'])\n",
    "  data_words_ret=list(sent_to_words(data))\n",
    "  for wd in data_words_ret:\n",
    "    data_words.append(wd)\n",
    "print (data_words[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1465,
     "status": "ok",
     "timestamp": 1590247435854,
     "user": {
      "displayName": "Randall Reed",
      "photoUrl": "",
      "userId": "15553862248564132325"
     },
     "user_tz": 240
    },
    "id": "PCIKdjewNzt6",
    "outputId": "192dfb0b-006c-447f-f30a-5491e9688b94"
   },
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MWiBTaMhN8dM"
   },
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "69IXaFOgN9Qc"
   },
   "outputs": [],
   "source": [
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GvYvBxBFOB2-"
   },
   "outputs": [],
   "source": [
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V-zFn_2MOGU8"
   },
   "outputs": [],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yCIxp3UXOKXs"
   },
   "outputs": [],
   "source": [
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bMRcpMo7OM5o"
   },
   "outputs": [],
   "source": [
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2849,
     "status": "ok",
     "timestamp": 1590247451333,
     "user": {
      "displayName": "Randall Reed",
      "photoUrl": "",
      "userId": "15553862248564132325"
     },
     "user_tz": 240
    },
    "id": "iR9ppTjjOQj_",
    "outputId": "68f8b2bf-5788-41a2-85fe-04f5652e2711"
   },
   "outputs": [],
   "source": [
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 887,
     "status": "ok",
     "timestamp": 1590247452970,
     "user": {
      "displayName": "Randall Reed",
      "photoUrl": "",
      "userId": "15553862248564132325"
     },
     "user_tz": 240
    },
    "id": "YCw-ax7CaXkN",
    "outputId": "e51397e9-0f68-4b3d-b4b6-9ec3bb740177"
   },
   "outputs": [],
   "source": [
    "print(len(data_lemmatized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1259,
     "status": "ok",
     "timestamp": 1590247455385,
     "user": {
      "displayName": "Randall Reed",
      "photoUrl": "",
      "userId": "15553862248564132325"
     },
     "user_tz": 240
    },
    "id": "1RU4eYQjag5x",
    "outputId": "485ea0ed-02ab-445d-9095-e9df01b493ab"
   },
   "outputs": [],
   "source": [
    "print(data_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TWqvw5PmOXa2"
   },
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DxT4cuHEObJA"
   },
   "outputs": [],
   "source": [
    "# Create Corpus\n",
    "texts = data_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2AlACCbcOdx7"
   },
   "outputs": [],
   "source": [
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1044,
     "status": "ok",
     "timestamp": 1590247464558,
     "user": {
      "displayName": "Randall Reed",
      "photoUrl": "",
      "userId": "15553862248564132325"
     },
     "user_tz": 240
    },
    "id": "A_6F6wMpOglY",
    "outputId": "32617883-6e02-447e-d71a-e75c709b494f"
   },
   "outputs": [],
   "source": [
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1226,
     "status": "ok",
     "timestamp": 1590247466824,
     "user": {
      "displayName": "Randall Reed",
      "photoUrl": "",
      "userId": "15553862248564132325"
     },
     "user_tz": 240
    },
    "id": "llCKGKTOOocq",
    "outputId": "f1e26ddd-8337-4a7f-e674-f64bb47f8941"
   },
   "outputs": [],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "157HfU13iRtK"
   },
   "source": [
    "## build model\n",
    "[parameters description here](https://radimrehurek.com/gensim/models/ldamodel.html#gensim.models.ldamodel.LdaModel.top_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 842,
     "status": "ok",
     "timestamp": 1590247471880,
     "user": {
      "displayName": "Randall Reed",
      "photoUrl": "",
      "userId": "15553862248564132325"
     },
     "user_tz": 240
    },
    "id": "A7W8Fcco8UZB",
    "outputId": "9071ab23-ccb6-40eb-eb62-454ee0ee43ec"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "sweep_config={\n",
    "    \"method\":\"random\",\n",
    "    \"metric\":{\n",
    "        \"name\":\"coherence\",\n",
    "        \"goal\":\"maximize\"\n",
    "    },\n",
    "    \"parameters\":{\n",
    "        \"num_topics\":{\n",
    "            \"values\":[10,20,30,40,50]\n",
    "        },\n",
    "        'random_state':{\n",
    "            \"values\":[50,52,54,56,58,60]\n",
    "        },\n",
    "        'update_every':{\n",
    "            \"values\":[1,5,10,50]\n",
    "        },\n",
    "        'chunksize':{\n",
    "            \"values\":[10,20,30,40,50,60,70,80,90,100]\n",
    "        },\n",
    "        'passes':{\n",
    "            'values':[10,20,30,40,50]\n",
    "        },\n",
    "        'minimum_probability':{\n",
    "            'values':[0.01,0.03,0.04,0.05,0.08]\n",
    "        },\n",
    "        'per_word_topic':{\n",
    "            'value':True\n",
    "        }\n",
    "    }\n",
    "}\n",
    "sweep_id = wandb.sweep(sweep_config, entity=\"reedrw\", project=\"gpt2-lda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oXVI9yVlOrLP"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "  # Build LDA model \n",
    "  config_defaults={\n",
    "      \"num_topics\":10,\n",
    "      \"random_state\":60,\n",
    "      \"update_every\":50,\n",
    "      \"chunksize\":10,\n",
    "      \"passes\":40,\n",
    "      \"minimum_probability\":.01,\n",
    "      \"per_word_topics\":True\n",
    "  }\n",
    "  wandb.init(config=config_defaults)\n",
    "  #print(\"run:\",run.config)\n",
    "  #print(\"type\",type(run))\n",
    "  #print(wandb.config)\n",
    "  #print(\"config=\",config)\n",
    "  config=wandb.config\n",
    "  \n",
    "  lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                            id2word=id2word,\n",
    "                                            num_topics=config.num_topics, \n",
    "                                            random_state=config.random_state,\n",
    "                                            update_every=config.update_every,\n",
    "                                            chunksize=config.chunksize,\n",
    "                                            passes=config.passes,\n",
    "                                            alpha=\"auto\",\n",
    "                                            minimum_probability=config.minimum_probability,\n",
    "                                            per_word_topics=config.per_word_topics)\n",
    "  # Print the Keyword in the 10 topics\n",
    "  wandb.log({\"topics\":lda_model.print_topics()})\n",
    "  doc_lda = lda_model[corpus]\n",
    "  coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence=\"c_v\")\n",
    "  coherence_lda = coherence_model_lda.get_coherence()\n",
    "  print(coherence_lda,)\n",
    "  wandb.log({\"coherence\":coherence_lda,\n",
    "             \"perplexity\":lda_model.log_perplexity(corpus)})\n",
    "  print(lda_model.print_topics()) \n",
    "  return lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "h-QdopQ2IUdS",
    "outputId": "86ab877e-fd93-4111-ceee-87a9fe8d063d"
   },
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model=train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6131,
     "status": "ok",
     "timestamp": 1590168774296,
     "user": {
      "displayName": "Randall Reed",
      "photoUrl": "",
      "userId": "15553862248564132325"
     },
     "user_tz": 240
    },
    "id": "h64GgPtSO0vs",
    "outputId": "0953ecb9-ce8f-4cd1-82e2-60e09e1cddcf"
   },
   "outputs": [],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "#wandb.log({\"topics\":lda_model.print_topics()})\n",
    "for l in lda_model.print_topics():\n",
    "    print(l)\n",
    "    \n",
    "#print(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4768,
     "status": "ok",
     "timestamp": 1590168777908,
     "user": {
      "displayName": "Randall Reed",
      "photoUrl": "",
      "userId": "15553862248564132325"
     },
     "user_tz": 240
    },
    "id": "_lWy5bN3O-Fw",
    "outputId": "e0f6b801-6d45-4736-fd7a-5e22b0a5cd6b"
   },
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "wandb.log({\"coherence\":coherence_lda})\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "if len(cohere)>0:\n",
    "  if max(cohere)<coherence_lda:\n",
    "    print('model improved')\n",
    "  else:\n",
    "    print('no improvement')\n",
    "else:\n",
    "  print('baseline established')\n",
    "cohere.append(coherence_lda)\n",
    "\n",
    "lda_model.save('lda_gpt2_model')\n",
    "wandb.save(\"lda_gpt2_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 861
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4406,
     "status": "ok",
     "timestamp": 1590085524986,
     "user": {
      "displayName": "Randall Reed",
      "photoUrl": "",
      "userId": "15553862248564132325"
     },
     "user_tz": 240
    },
    "id": "l0naI6a2PDUW",
    "outputId": "42531d24-96f1-4f4b-f1c0-ac91ff319b41"
   },
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "viz = pyLDAvis.display(LDAvis_prepared)\n",
    "\n",
    "viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mallet LDA ##\n",
    "[see guide here](https://radimrehurek.com/gensim/models/wrappers/ldamallet.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "mallet_sweep_config={\n",
    "    \"method\":\"bayes\",\n",
    "    \"metric\":{\n",
    "        \"name\":\"coherence\",\n",
    "        \"goal\":\"maximize\"\n",
    "    },\n",
    "    \"parameters\":{\n",
    "        \"num_topics\":{\n",
    "            \"values\":[10,20,30,40,50]\n",
    "        },\n",
    "        \"iterations\":{\n",
    "            'min':1,\n",
    "            'max':20\n",
    "           },\n",
    "        \"alpha\":{\n",
    "            \"values\":[0.7,0.8,0.9,1,1.1,1.2]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "mallet_sweep_id = wandb.sweep(mallet_sweep_config, entity=\"reedrw\", project=\"gpt2-lda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nUImFKCeQKpu"
   },
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_corpus, common_dictionary\n",
    "from gensim.models.wrappers import LdaMallet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mallet_train():\n",
    "    default_config={\n",
    "        'path_to_mallet_binary':'~/Downloads/Mallet/bin/mallet',\n",
    "        'num_topics':50,\n",
    "        'iterations':1,\n",
    "        'alpha':1.2\n",
    "        }\n",
    "    wandb.init(config=default_config)\n",
    "    config=wandb.config\n",
    "    ldamallet = gensim.models.wrappers.LdaMallet(path_to_mallet_binary, corpus=corpus, num_topics=config.num_topics, \n",
    "                                                 iterations=config.iterations, alpha=config.alpha, id2word=id2word, random_seed=1000)\n",
    "    coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "    coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "    print('\\nCoherence Score: ', coherence_ldamallet)\n",
    "    wandb.log({\"topics\":ldamallet.show_topics(),\n",
    "              \"coherence\":coherence_ldamallet})\n",
    "    #pprint(ldamallet.show_topics())\n",
    "    return ldamallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(mallet_sweep_id,mallet_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamallet=mallet_train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Topics\n",
    "pprint(ldamallet.show_topics())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNzPUXa8vb6Gx7ZqJ4cBXJb",
   "name": "gensim gpt2 lda.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
